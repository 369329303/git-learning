golang 语言部分

1. golang的堆内存管理？
```
    1. 采用TCMalloc的分配方式，核心理念是使用多级缓存，根据对象大小分类，并按照类别实施不同的分配策略。
    2. 对象大小：
        微对象：(0, 16B)
        小对象：[16B, 32KB]
        大对象：(32KB, ...)
      程序中的对象大部分都在32KB以下，而分配内存的大小影响Go语言分配时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。
    3. TCMalloc和Go引入线程缓存(Thread Cache)，中心缓存(Central Cache)和页堆(Page Heap)三个组件来分级管理内存。
       线程缓存属于每一个独立的处理器P，它能够满足绝大多数的内存分配需求，因为不涉及多线程，所以也不需要互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。
       当线程缓存不能够满足需求时，就会使用中心缓存作为补充解决小对象的内存分配问题；当遇到32KB以上的对象时，内存分配器就会选择页堆直接分配大量的内存。
    4. 使用稀疏内存布局，移出了线性内存布局下堆大小的上线，还解决了C和Go混合使用时地址空间冲突问题。
    5. 每一个P都会被分配一个线程缓存 runtime.mcache 用于处理微对象和小对象的分配，它们持有内存管理单元 runtime.mspan.
       每个内存管理单元都会管理特定大小的对象，当内存管理单元不存在空闲对象时，就会从 runtime.mheap 持有的 134 个中心缓存 runtime.mcentral 中获取新的内存单元。
       中心缓存从属于全局的堆结构体 runtime.mheap，他会从操作系统中申请内存。
       Go语言的内存管理模块一共包含67种跨度类，每一个跨度类都会存储特定大小的对象，并且包含特定数量的页数.
       跨度类除了存储类别的ID之外，还会存储一个noscan标志位，该标志位表示对象是否包含指针，GC只会対包含指针的 runtime.mspan 进行扫描
    6. 线程缓存：runtime.mcache 是Go中的线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。每一个线程缓存都持有67*2个runtime.mspan
    7. 中心缓存：runtime.mcentral 是Go中的中心缓存，与线程缓存不同，访问中心缓存的内存管理单元需要使用互斥锁。
       每一个中心缓存都会管理某个跨度类的内存管理单元，它会同时持有两个 runtime.mSpanList 分别存储包含空闲对象和不包含空闲对象的链表
    8. 页堆：runtime.mheap 是内存分配的核心结构体，堆上存在的所有对象都是由该结构体进行管理的。它包含两个非常重要的字段，一个是全局的中心缓存列表 central， 另一个是
       管理堆区内存区域的arenas。
       页堆中包含一个长度为134的 runtime.mcentral 数组，其中 67 个为需要 scan 的中心缓存，67个为不需要 scan 的中心缓存。
```

2. golang的垃圾回收机制？
```
    1. Sweep Termination: 清扫终止阶段。如果当前程序是强制触发的，我们还需要处理未被清理的内存管理单元。
    2. Mark：标记阶段。
        2.1 开启写屏障，用户程序协助，并将根对象入队。
        2.2 恢复用户程序，标记进程和协助进程开始标记内存中的对象，写屏障会将修改的指针标记为灰色，而新创建的指针会被标记为黑色。
        2.3 扫描根对象，包括所有Goroutine的栈，全局对象。扫描Groutine的栈期间，暂停当前处理器。
        2.4 依次处理灰色队列中的对象，将对象标记为黑色，并将它们指向的对象标记为灰色。
        2.5 检查灰色队列是否为空，不为空则继续标记，否则进入标记终止阶段
    3. Mark Termination: 标记终止阶段，暂停程序，关闭写屏障和用户程序协助
    4. Sweep：清理阶段
        4.1 恢复用户程序，所有新创建的对象都会被标记为白色
        4.2 后台并发清理内存(还有一种懒惰清理，边分配内存边清理)

    5. 触发时机：
        5.1 堆目标：分配的内存翻了一倍
        5.2 时间目标：每隔2min
        5.3 手动触发：runtime.GC()
    6. 虽然指针比值传参数所消耗内存要小，但是会增加垃圾回收器的负担。所以如果对象比较小的话，应该使用值传参。
```
3. golang是如何调度Goroutine的？
```
    1. 线程是通过共享内存进行通信的，而Goroutine可以通过通信来共享内存
    2. Go 语言的调度器通过使用与CPU数量相等的线程减少线程频繁切换的开销，同时在每一个线程上执行开销更低的Goroutine来降低对于操作系统和硬件的负载。
    3. 单线程调度器(0.x)，多线程调度器(1.0)，任务窃取调度器(1.1)，抢占式调度器(1.2-至今)，非均匀存储访问调度器(提案)
    4. 任务窃取调度器：G-M-P模型
        4.1 G-M-P模型中引入的处理器P是线程和Goroutine的中间层，处理器持有一个由可运行的Goroutine组成的运行队列 runq，还反向持有一个线程。
            调度器调度时，会从处理器的runq队列中选择队列头的Goroutine放到线程M上。
        4.2 基于工作窃取的多线程调度器将每一个线程绑定到了独立的CPU上，这些线程会被不同的处理器管理，不同的处理器通过工作窃取实现任务再分配
    5. 抢占式调度：
        5.1 在之前的1.1版本中，为非抢占式调度。程序只能够依靠Goroutine主动让出CPU资源才能触发调度。存在以下问题：
            5.1.1 某些Goroutine可以长时间的占用线程，造成对应P的runq中其它Goroutine的饥饿
            5.1.2 GC的STW阶段耗时太长
        5.2 基于协作的抢占式调度：通过编译器插入函数实现
            5.2.1 Go 语言运行时会在GC时暂停程序，系统监控Goroutine，运行超过10ms发出抢占请求 StackPreempt
            5.2.2 当发生函数调用时，可能会执行编译器插入的 runtime.morestack 函数，它调用的 runtime.newstack 会检查Goroutine的 stackguard0 字段是否为
                  StackPreempt;
            5.2.3 如果 stackguard0 是 StackPreempt，就会触发抢占让出当前P。
        5.3 基于信号的抢占式调度：还有一些问题没有解决
    6. 数据结构
        6.1 G - Goroutine，表示一个待执行的任务
                type g struct {
                    stack       stack   // 描述当前Goroutine的栈内存范围[stack.lo, stack.hi)
                    stackguard0 uintptr // 用于抢占式调度
                    _panic      *_panic
                    _defer      *_defer
                }
        6.2 M - 操作系统线程，由操作系统的调度器调度和管理
            6.2.1 调度器最多可以创建10000个线程，但是最多只会有GOMAXPROCS个活跃线程能够正常运行
            6.2.2 g0 是持有调度栈的Goroutine，curg 是在当前线程上运行的用户Goroutine
                type m struct {
                    g0 *g
                    curg *g 
                    ...
                }
        6.3 P - 处理器，可以被看作是运行在线程上的本地调度器
            6.3.1 提供线程需要的上下文环境，负责调度线程上的等待队列
    7 全局和本地运行队列
        7.1 Go语言中有两个运行队列，其中一个是处理器的本地运行队列，另一个是调度器持有的全局运行队列，只有在本地运行队列没有剩余
            空间（最多可以存储256个待执行Goroutine，它是一个环形队列）时才会使用全局队列。
        7.2 公平层次
            Goroutine - 抢占式
            本地运行队列 - 时间片 10ms
            全局运行队列 - 通过 schedtick%61 保证有一定概率选择一个
            网络轮询器 - 后台线程检查网络准备状态是否就绪
            随机从其它处理器的runq中窃取一部分Goroutine

            1. globrunqget(_g_.m.p.ptr(), 1)  // schedtick % 61
            2. runqget(_g_.m.p_ptr())   // runnext
            3. findRunnable() // 阻塞
                3.1 runqget(_p_)    // 本地队列中取一个
                3.2 globrunqget(_p_, 0) // 从全局队列中取出一部分
                3.3 netpoll(0)      // 就绪态的网络连接中取出一个
                3.4 runqsteal(_p_, p2, strealRunNextG)  // 从其它本地队列中偷一半
    8 调度触发条件
        8.1 当前Goroutine主动挂起
        8.2 系统调用
        8.2 协作式调度
        8.3 系统监控

```
4. golang是如何进行并发控制的？
```
    1. 全局变量
    2. channel 和 sync.WaitGroup
    3. context包
        3.1 context.Context 是用来设置截止时间，同步信号，传递相关值的接口
        3.2 context.Context 定义了四个需要实现的方法
            type Context interface {
                Deadline() (deadline time.Time, ok bool)    // 返回context.Context 被取消的时间
                Done() <-chan struct{}  // 返回一个channel,这个channel会在当前工作完成或者上下文被取消之后关闭，多次调用Done方法会返回同一个channel
                Err() error // 返回结束的原因。被取消：返回Canceled错误；超时：返回 DeadlineExceeded错误         
                Value(key interface{}) interface{}  // 获取建对应的值，用来传递数据
            }
        3.3 在Goroutine构成的树形结构中対信号进行同步以减少计算资源的浪费是context.Context的最大作用。
```
5. golang中的slice类型介绍一下？扩容机制？
```
    1. 在编译期确定切片内元素类型
    2. 数据结构
        type SliceHeader struct {
            Data uintptr
            Len int
            Cap int
        }
    3. 当切片非常大或者发生逃逸时，会被分配在堆上
    4. 扩容策略
        4.1 如果期望容量大于当前容量的两倍，直接使用期望容量
        4.2 如果当前容量小于1024，容量翻倍
        4.3 如果当前容量大于1024就会每次增加25%的容量，直到新容量大于期望容量
```
6. golang中的defer关键字介绍一下？
```
    1. defer 传入的函数不是在退出代码块的作用域时执行的，它只会在当前函数或方法返回前被调用。
    2. deder 会对函数参数进行预计算
    3. defer 在编译器看来也是函数调用
    4. 遇到defer 关键字的时候，会创建一个 _defer 数据结构(会对函数参数进行预计算)，但是还没有加入到 defer 链上，在栈搭建完成之后，会从栈顶向栈底扫描defer结构，
       逐个添加到defer链中。在函数返回时，会判断defer链是否为空。如果不为空，就依次从链头defer执行到链尾defer；否则，直接退出函数。
```
7. golang中的接口？
```
    1. 接口的实现都是隐式的
    2. interface{} 类型不是任意类型
        eface结构体表示不包含任何方法的结构体,iface结构体表示包含方法的结构体.
        type eface struct {
            _type *_type
            data  unsafe.Pointer
        }

        type iface struct {
            tab *itab
            data unsafe.Pointerk
        }
    3. 指针类型的方法是无法被结构体类型对象调用的。
    4. 类型断言：
        4.1 对于eface 来说，通过比较eface._type.hash 与 目标类型的 hash 进行比较
        4.2 对于iface 来说，通过比较iface.tab.hash 与 目标类型的 hash 进行比较
    5. 使用结构体来实现接口的开销会大于使用指针实现，动态派发(Dynamic Dispatch)在结构体上的表现非常差
```
8. gRPC框架 是什么？
```
grpc是一个由Google开源的，高性能，支持多语言的RPC框架。基于HTTP/2协议设计，单TCP连接上多个双向Stream，头部压缩功能。
调用模型：
    1. 客户端调用方法A，发起RPC调用
    2. 对请求信息使用protobuf对数据进行序列化
    3. 服务端收到请求后，反序列化，获得请求，执行业务逻辑处理并返回应答
    4. 对应答信息使用protobuf再次序列化然后发给客户端
调用方式：
    1. 一元RPC
    2. 服务端流式RPC
    3. 客户端流式RPC
    4. 双向流式RPC
常见问题：
    1. grpc.Dial 是异步连接，状态为正在连接，但如果设置了grpc.WithBlock选项，就会阻塞等待直到连接建立。
    2. 调用ClientConn不Close会导致内存泄漏
    3. 如果不进行超时控制的话，短时间内不会有问题，但如果时间长了，就会造成内存泄漏
    4. 默认的拦截器可以传递多个，但是只有第一个有用。
    5. 频繁创建ClientConn会造成占用过多的文件句柄。
    6. 客户端请求失败会重试，直到上下文取消，重试时间采用backoff算法，最大重试时间为120s。
    7. gRPC的附加信息都会放在HEADERS帧中，数据放在DATA帧中
```
9. Go 中map的实现原理？
```
    1. 采用桶装法
        type hmap struct {
            count     int       // 当前哈希表中的元素个数
            flags     uint8
            B         uint8     // 当前哈希表持有的正常buckets数量的log值，len(buckets) == 2 ^ B 
            noverflow uint16    // 溢出桶的数量
            hash0     uint32    // 哈希的种子，为哈希函数的结构引入随机性，在创建哈希表的时候确定

            buckets    unsafe.Pointer   // 保存正常桶的基地址
            oldbuckets unsafe.Pointer   // 哈希在扩容时用于保存之前buckets的基地址
            nevacuate  uintptr          // 哈希表在扩容时，已经迁移走的元素数量

            extra *mapextra             // 包含了溢出桶的基地址
        }

        type bmap struct {      // 桶的结构体，编译期间重构的结果
            topbits  [8]uint8   // 每个桶中存储8个键值対，存储了键的哈希值的高8位
            keys     [8]keytype
            values   [8]valuetype
            pad      uintptr
            overflow uintptr    // 下一个溢出桶的地址
        }
        如果哈希表中存储的元素主键增多，会使用溢出桶或者扩容
    2. 读操作
        v     := hash[key] // => v     := *mapaccess1(maptype, hash, &key)
        v, ok := hash[key] // => v, ok := mapaccess2(maptype, hash, &key)
        在编译期根据左边变量的个数来确定使用那种方法。
    3. 扩容策略
        3.1 触发条件
            3.1.1 装载因子超过6.5，存储的元素数量/正常桶的数量，这个计算方法有点奇怪
            3.1.2 哈希使用了太多的溢出桶
        3.2 扩容不是一个原子过程，是一个增量过程，不会造成性能的巨大抖动。读操作不会触发扩容，写操作会触发扩容。
```
10. set实现一下？
11. Go 的栈内存管理？
```
    1. i386 和 x86_64架构的机器上，默认的线程 栈大小是2MB。而Goroutine的栈大小最小为2KB，可以动态调整，最大达到1GB。
    2. 逃逸分析
        2.1 逃逸分析是用来决定指针的动态作用域。Go语言编译器使用逃逸分析来决定哪些变量应该在栈上分配，哪些应该在堆上分配。
        2.2 两个不变性：
            2.2.1 指向栈对象的指针不能够存在于堆中
            2.2.2 指向栈对象的指针不能够在在对象被回收后存活
        2.3 使用 go build --gcflags="-m -m" 来确定变量到底是分配在了哪里。
        2.4 一般函数返回的指针变量和非常大的变量会分配在堆上。
    3. 栈的动态扩容是通过栈分裂和栈增长实现的。
    4. 对于<32KB 的对象，per M cache来分配，避免锁竞争；>32KB的对象，从全局栈中分配，还不够就从堆分配。

```
12. Go 的同步原语与锁
```
    1. 基本原语：sync.Mutex, sync.RWMutex, sync.WaitGroup, sync.Once, sync.Cond.
    2. 互斥锁，任意时刻只能被一个Goroutine所持有。
    3. 读写锁，可以并发读，但是不能并发写或者读写。
    4. sync.WaitGroup 等待一组Goroutine的返回，常用场景如批量发出RPC或HTTP请求
    5. sync.Once 保证Go程序运行期间的某段代码只会执行一次。
        5.1 使用了互斥锁和sync/atomic包提供的方法Load/Store.
        5.2 两次调用sync.Once.Do方法传入不同的函数也只会执行第一次传入的函数
    6. sync.Cond 不常用。
        6.1 sync.Cond.Wait 方法在调用之前一定要先获取互斥锁，否则程序会崩溃，不能unlock一把已经unlocked的锁
        6.2 sync.Cond.Signal 方法唤醒的Goroutine是等待队列最前面的Gouroutine
        6.3 sycn.Cond.Broadcast 会唤醒所有的Goroutine
```
13. Go 的网络轮询器
```
    1. 网络轮询器用于监控网络IO和文件IO。
    2. 阻塞IO：最常见的IO模型，対文件和网络的读写操作默认情况下，都是阻塞的。当执行read系统调用时，应用程序从用户态陷入内核态，直到文件描述符
       中的数据准备好之后，才会返回用户态。
    3. 非阻塞IO：当执行read系统调用时，应用程序会不断的向操作系统询问数据是否已经准备好了，准备好了之后就会从内核态中取回数据。在等待过程中，CPU
       可以执行其它任务。
    4. IO多路复用：用来处理同一事件中的多个IO事件。多路复用函数(select)会阻塞地监听一组文件描述符，当文件描述符转变为可读或可写后，
       select 会返回可读或者可写事件的个数，应用程序就可以在输入的文件描述符中，查找哪些可读或者可写，然后执行相应操作。
```

14. Go 系统监控
```
    1. 任务
        1.1 检查死锁
        1.2 运行计时器： 获取下一个需要被触发的计时器
        1.3 轮询网络：获取需要处理的到期文件描述符
        1.4 抢占处理器：抢占运行时间较长的或者处于系统调用的Goroutine
        1.5 垃圾回收：在满足条件时触发垃圾回收机制
```
15. Go 函数调用 
```
    1. 通过堆栈传递参数，入栈的顺序是从右到左
    2. 调用函数是都是传值。
    3. 数组在进行参数传递的时候，实际上会拷贝一整份数组，但是在for-range的时候却不是拷贝，因此建议不要使用数组。
```

16. for 和 range
```
    1. 可以快速遍历数组，切片，哈希表以及channel等集合类型
    2. range循环中，Go语言会在编译期将原切片或者数组赋值给一个新的变量ha，在赋值的过程中发生了拷贝，
       我们遍历的切片变量已经不是原来的切片变量了。
```

17. Go 语言中 new 和 make的区别
```
    1. make的作用是用来初始化内置的数据结构，包括slice, map, channel
    2. new 的作用是根据传入的类型分配一块内存空间并返回指向这块内存空间的指针
```

操作系统部分：
1. 死锁产生的条件及如何避免死锁？
2. 进程，线程，协程的区别？
3. LVS有哪几种模式？各有什么特点？
```
    3.1 NAT 模式：RS和DS位于同一个网段内，DS是RS的网关。请求和回答都得经过DS，DS是系统瓶颈。
    3.2 TUN 模式：RS和DS通过IP管道来进行传输，可以不在同一个局域网内，有利于异地容灾。请求经过DS，但应答不经过DS。由于管道增加了数据量。
    3.3 DR 模式： RS和DS位于同一个网段内，通过修改MAC地址来进行DS到多个RS的路由。请求经过DS，但应答不经过DS。目前应用的最多。
```
4. Keepalived介绍一下？
```
    4.1 VRRP 虚拟路由冗余协议：将多个路由器设备虚拟成一个设备，对外提供一个或多个虚拟IP地址。这些路由器设备中只有一个是master，其余都是slave。
        master会定时向slave发送VRRP通告信息，表明自己还活着。如果一段时间内没有收到，slave之间会通过VRRP通告来选取出一个新的master。
    4.2 VRRP数据包的目标IP地址必须是224.0.0.18（广播地址）.
    4.3 keepalived程序有三个进程。其中父进程负责内存管理。子进程1负责VRRP协议的实现，负责master/slave的切换。子进程2负责健康检查，如HTTP服务器是否存活。
    4.4 虚拟IP的出现是根据master/slave的状态确定的。
```

网络方面：
1. select, poll, epoll 之间的区别在哪里？
2. HTTP/1.1 于 HTTP/2 的区别？
```
    1. HTTP/1.1 是1999年提出的，HTTP/2 是2015年提出的。
    2. 影响HTTP网络请求的因素主要有两个，带宽和延迟。现在已经不是拨号上网的年待了，所以带宽不再是一个因素；延迟，DNS查询可以通过DNS缓存来解决。Head Of Line 阻塞，一个连接上无法跑多个请求都是问题。
    3. 多路复用：HTTP/1.1的pipeline机制虽然可以在一个TCP连接上跑多个请求，但是无法并发，容易产生HOL阻塞。而HTTP/2的多路复用是将请求分散，当作流来处理，每个请求对应不同的流，实现了请求的并发，并不会造成HOL阻塞。
    4. 首部压缩 ：HTTP/1.1的首部是不压缩的，并且多个请求通常都包含相同的首部。这对于带宽和延迟都很浪费。而HTTP/2通过在客户端和服务端分别维护一个动态字典和一个静态字典，用字符代替请求头来传输，降低带宽和延迟。
    5. 服务器推送：HTTP/1.1中客户端请求main.html，服务端仅返回main.html,但是HTTP/2会同时返回main.html, main.css等。这样客户端下次请求main.css的时候直接在缓存中就可以找到了。
    6. 可以传递二进制信息
```
3. TCP共有哪些状态？
```
    closed      listen
 
    syn_send   
                syn_recv
    established 
                established
           ========
    fin-wait-1
                close-wait
    fin-wait-2  
                last-ack
    time-wait    

    此外closing 状态比较少见，属于同时发送FIN包的情况。之后只要同时收到对方发来的ACK包，就可以进入time-wait状态.
```

4. TCP握手和挥手的过程说一下？
```
    握手过程：
    ->    syn(SYN=x)
    <-    syn+ack(SYN=y, ACK=x+1)
    ->    ack(ACK=y+1)

    挥手过程：
    ->    fin(SYN=x)
    <-    ack(ACK=x+1)
    <-    fin(SYN=y)
    ->    ack(ACK=y+1)    

```
5. HTTP的状态码有那些？301和302的区别？401和403的区别？502和504的区别？
```
    1xx:
        100: 继续
        101: 切换协议（比如websocket）
    
    2xx：
        200: 成功
        206: 部分信息
    3xx：
        301: 永久移动
        302：临时移动
        304: 文件未修改
        307: 和302相同，但是会使用get来代替post
    4xx：
        400: 请求方法或参数不正确
        401: 未认证
        403: 权限不够
        404: 未找到
    5xx：
        500: 服务器内部错误
        502: 服务器作为网关或代理，从上游服务器收到无效应答
        504: 服务器作为网关或代理，从上游服务器接收应答超时
        505: 请求的HTTP协议版本不支持

```

6. Cookie和Session的区别？
```
    Cookie：服务器在客户端上存储的小段文本，并随着每一个请求发送至同一个服务器。cookie的内容包括名，值，过期时间，路径和域。默认过期时间是浏览器会话期间。
    Session：服务器利用散列表来保存Session信息。
    区别：
        1. 都是保存用户状态的技术
        2. Cookie一般用来存放ASCII，而Session可以用来存放二进制信息。
        3. 隐私策略不同：Cookie存放在客户端，客户端的某些程序能够读和写Cookie；而Session放在服务端，对于客户端是透明的，更加安全。
        4. 服务器压力不同：如果用户量特别多的化， 会给服务器增加负担。
        5. Session既可以通过在URL中添加SessionID的方式实现，也可以通过在Cookie中添加SessionID这一项。
        6. 单个Cookie在客户端的限制是3K，而Session没有限制。

```
7. TCP和UDP的区别？
```
    1. TCP是有状态的，UDP没有状态
    2. TCP是可靠的，UDP不可靠
    3. TCP报文比较大，UDP比较小
    4. TCP是面向字节流的，UDP是面向报文的。
```
8. TIME-WAIT的作用？
```
    1. 保证对方能够收到ACK报文，正确断开连接
    2. 避免新老连接混在一起，影响新连接的建立。
```
9. CLOSE-WAIT太多怎么办？
```
    1. 查代码，实现有问题。FIN包没有发送出去，可能是由于socket没有正常关闭。
```
10. 输入 ping IP 后，在发包之前会发生什么？
```
    1. 查询路由表，决定从哪个网卡出去。
    2. 判断是否在局域网内
        2.1 如果在局域网内，查询arp表，如果查到了，直接发出去；否则向局域网内发arp广播查询该IP地址对应的MAC地址，查到后缓存该IP-MAC対，并发出去。
        2.2 如果不在局域网内，填入网关的MAC地址发出去。
```
11. 建立一个socket要经过哪些步骤？
```
    1. 服务器和客户端分别调用 int socket(int domain, int type, int protocol); 建立一个socket.
    2. 服务器和客户端分别调用 int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 将socket 绑定到本地的一个地址上面来。
    3. 服务器上用 int listen(int sockfd, int backlog); 开启socket监听,等待客户端的连接
    4. 客户端上用 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 连接服务器
    5. 服务器上用 int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 建立起一个socket连接
    6. 服务器和客户端分别调用 ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 来进行通信。
    7. 服务器和客户端均可以调用 int close(int fd); 来关闭连接
```
12. TLS的握手过程详细说一下？
```
    TLS1.2 完整握手过程：
      Client                                               Server

      ClientHello                  -------->
                                                      ServerHello
                                                     Certificate*
                                               ServerKeyExchange*
                                              CertificateRequest*
                                   <--------      ServerHelloDone
      Certificate*
      ClientKeyExchange
      CertificateVerify*
      [ChangeCipherSpec]
      Finished                     -------->
                                               [ChangeCipherSpec]
                                   <--------             Finished
      Application Data             <------->     Application Data

             Figure 1.  Message flow for a full handshake

    1. ClientHello 和 ServerHello 用来定义协议版本，Session ID， 算法套件，压缩方法，还有两个随机数。
    2. 密钥交换需要Server Certificate, ServerKeyExchange, Client Certificate, ClientKeyExchange四个消息。
    3. 第一个被加密的信息是Client Finished。
    4. SessionID 在ServerHello 中。
    5. DHE能够提供FS (Forward Secrey) 前向安全，RSA不能够
    6. APLN存在ClientHello消息中，用来告诉服务器它所加密的上层协议类型。
    7. SNI存在ClientHello消息中，用来解决一个IP地址上多个域名的问题。
    8. Session重用通过Session ID和 Session Ticket的方式解决

    TLS1.2 恢复握手过程：
      Client                                                Server

      ClientHello                   -------->
                                                       ServerHello
                                                [ChangeCipherSpec]
                                    <--------             Finished
      [ChangeCipherSpec]
      Finished                      -------->
      Application Data              <------->     Application Data

          Figure 2.  Message flow for an abbreviated handshake
    
    1. ClientHello 中存放着之前的Session ID信息。
    2. 此时必须要发送ChangeCipherSpec消息


    TLS1.3 握手过程：
       Client                                           Server

Key  ^ ClientHello
Exch | + key_share*
     | + signature_algorithms*
     | + psk_key_exchange_modes*
     v + pre_shared_key*       -------->
                                                  ServerHello  ^ Key
                                                 + key_share*  | Exch
                                            + pre_shared_key*  v
                                        {EncryptedExtensions}  ^  Server
                                        {CertificateRequest*}  v  Params
                                               {Certificate*}  ^
                                         {CertificateVerify*}  | Auth
                                                   {Finished}  v
                               <--------  [Application Data*]
     ^ {Certificate*}
Auth | {CertificateVerify*}
     v {Finished}              -------->
       [Application Data]      <------->  [Application Data]

              +  Indicates noteworthy extensions sent in the
                 previously noted message.

              *  Indicates optional or situation-dependent
                 messages/extensions that are not always sent.

              {} Indicates messages protected using keys
                 derived from a [sender]_handshake_traffic_secret.

              [] Indicates messages protected using keys
                 derived from [sender]_application_traffic_secret_N.

               Figure 1: Message Flow for Full TLS Handshake



         Client                                               Server

         ClientHello
         + early_data
         + key_share*
         + psk_key_exchange_modes
         + pre_shared_key
         (Application Data*)     -------->
                                                         ServerHello
                                                    + pre_shared_key
                                                        + key_share*
                                               {EncryptedExtensions}
                                                       + early_data*
                                                          {Finished}
                                 <--------       [Application Data*]
         (EndOfEarlyData)
         {Finished}              -------->
         [Application Data]      <------->        [Application Data]

               Figure 4: Message Flow for a 0-RTT Handshake
    1. TLS1.2 需要2个rtt才能完成握手，TLS1.3只需要1个rtt就能完成握手。
    2. 移出了不安全的算法。只有DHE了。
    3. TLS1.2 需要1个rtt来完成Session重用，TLS1.3 的session重用只需要0个rtt
```

13. HTTP 的请求方式有那些，每个分别是什么意思？
```
    1. GET: 请求显示特定的资源，只用于数据读取，幂等操作
    2. POST：提交数据，如表单，文件。非幂等操作。
    3. HEAD：只获取响应头部，不获取响应主体。幂等。
    4. PUT：对已存在的资源更新。幂等。
    5. DELETE：删除指定资源。幂等。
    6. CONNECT：将服务器作为代理服务器连接
    7. OPTIONS: 探测服务器所支持的所有请求方法
    8. TRACE: 要求服务器回显其收到的信息
    9: PATCH: 若资源不存在，则创建；否则，更新。
```


数据库：
1. Redis的数据结构有哪几种，它们的底层实现是什么？
2. 聚簇索引和非聚簇索引介绍一下？
```
    1. 两者的区别在于叶子节点是否存放了一整行的数据
    2. InnoDB主键使用聚簇索引，二级索引使用的是非聚簇索引，MyISAM使用的都是非聚簇索引。
    3. 聚簇索引查找目标数据时，理论上比非聚簇索引更快
    4. 聚簇索引插入很慢，需要遍历所有节点，但是由于叶子节点上面的数据很大，会因此付出IO代价。
    5. 一张表只允许创建一个聚簇索引。默认采用主键索引作为聚簇索引。
```
3. B+树的结构介绍一下？
```
    1. B+树基于B树和叶子节点顺序访问指针进行实现，它具有B树的平衡性并能够通过顺序访问指针来提高区间查询的性能。
    2. 在B+树中，叶子节点的Key从左向右非递减排序。
    3. B+树需要通过分裂，合并，旋转的方式来维护平衡性。
    4. 与红黑树相比： 平衡树查找的时间复杂度与树高有关，而B+树的出度大，高度低，因此查找次数更少。而且区间查找更快速。
    5. 与B树相比，非叶子节点不存放值。因此，一次IO操作可以读入更多的节点。加速查找。而且叶子节点有序，通过指针连接，区间查找更快速。
```
4. Hash冲突的解决办法？
```
    1. 开放地址法
    2. 再哈希法
    3. 链地址法
    4. 建立公共缓冲区
```
5. Redis 持久化有哪几种方式？
```
    1. RDB方式：默认开启，Redis会按照配置的指定时间将内存中的数据写入道磁盘上，创建一个dump.rdb文件，Redis启动时再恢复到内存。
       Redis会fork出一个子进程，将当前父进程的数据库拷贝到子进程的内存中来，然后由子进程负责写入道临时文件，持久化的过程结束了，再用
       这个临时文件替换掉上次的快照文件成为新的快照。
    2. AOF方式：以日志的形式记录每条写操作，不记录读操作。Redis启动时会根据日志内容从头到尾的执行一遍，完成持久化。
       因为采用追加的方式，会使的文件越来越大，针对这个问题，新增了重写机制，当日志文件大到一定程度的时候，会fork出一条新进程遍历父进程
       内存中的数据，每条记录对应一条set语句，写入临时文件中，之后再替换原来的aof文件。默认触发条件是日志文件大小翻倍，并且大于64M。
```

6. Redis常见性能及解决方案？
```
    1. Master 最好不要做持久化工作，让Slave做。
    2. 如果数据比较重要，某个Slave开启AOF备份，策略设置为每秒同步一次。
    3. 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内。
    4. 主从复制不要采用图状结构，采用链状结构更稳定。方便解决单点故障。
```

7. Redis有哪几种淘汰旧数据的方案？
```
    1. volatile-ttl：从设置过期时间的数据集中选出最早要过期的
    2. volatile-lru: 从设置过期时间的数据集中选出最近最少使用的
    3. volatile-random: 从设置过期时间的数据集中随机选择一个
    4. allkeys-lru: 从整个数据集中选出最近最少使用的
    5. allkeys-random: 从整个数据集中随机选择一个
    6. noeviction: 不淘汰。
```

8. Redis 为什么是单线程的？
```
    1. 多线程涉及到锁，实现复杂。
    2. Redis的瓶颈在于内存和带宽，而不是CPU
    3. 虽然单进程无法发挥多核CPU的性能，但是可以通过在一个机器上开多个Redis来解决。
```

9. Redis 哨兵和复制？
```
    1. Sentinel可以管理多个Redis服务器，提供了监控，提醒，和自动的故障转移功能。
    2. Replication 负责让一个Redis服务器可以管理多个备份服务器。
```

10. Redis 哈希槽是什么？
```
    1. 当向Redis cluster中加入一个key，会根据crc16(key) mod 16384计算这个key应该放到哪个hash slot中，
       一个hash slot中会有很多的key和value。可以理解是表的分区。
    2. 便于动态的增加和删除节点，不需要停掉服务。
    3. key通过hash算法计算出应该放到哪个hash slot中，然后根据内存表来判断这个slot应该在哪个物理节点上。
    4. 哈希槽是16384（2^14）的原因：
        4.1 2^16个槽心跳信息达到8K，而2^14只有2K。
        4.2 crc16 対 2^14 取模，会使的key能够分布的很均匀。
        4.3 一个Redis集群通常不会超过1000个，那么一个节点上至少也有16个槽，可以分的到就行了。
    5. Redis集群最大节点数量也是16384 (2^14)个。
```

11. MYSQL的复制原理
```
    1. 主库上开启一个IO线程用于将写操作记录到二进制日志中。
    2. 从库上开启一个IO线程用于将主库上二进制日志中记录的写操作写入到自己的中继日志当中
    3. 从库上再开启一个SQL线程用于执行中继日志中的写操作，从而实现主从同步
    4. 二进制日志有三种格式
        4.1 语句格式
            4.1.1 使用了load_file(), uuid(), user(), sysdate() 的语句是无法记录的。
        4.2 行格式（可能会造成大量日志）
        4.3 语句和行混合格式（这个比较好）
```
12. InnoDB和MyISAM的区别？
```
    1. 事务的支持：InnoDB支持事务，MyISAM不支持事务。
    2. 锁的粒度：InnoDB为行级锁，MyISAM为标记锁。
    3. 索引类型：InnoDB为聚簇索引，MyISAM为非聚簇索引。
    4. 恢复完整度：InnoDB在数据库崩溃后容易恢复，MyISAM不容易恢复完整。
    5. 对于外键的支持：InnoDB支持，MyISAM不支持。
    6. 行数统计的快慢：InnoDB需要全表扫描，MyISAM可以从变量中直接读取。
    7. 存储结构：InnoDB中的所有表保存在同一个数据文件中。MyISAM中表分为.frm,.MYD,.MYI三个文件。
```
13. InnoDB存储引擎的四大特性
```
    1. 插入缓冲（Insert Buffer）：对于二级索引页的写操作，先保存在内存当中，等时机成熟在应用到二级索引页上。
    2. 二次写（Double Write）：将脏页先写入到二次写缓冲当中，然后在写入道共享表空间，最后才写入到独立表空间。保证
       数据页的可靠性。
    3. 自适应哈希索引（Adaptive Hash Index）：一般来说，我们实现从二级索引当中获取主键值，然后在聚簇索引当中获取行数据。
       我们可以対二级索引中的索引和行数据建立一个哈希关系。从而加快超找速度。
    4. 预读（Read Ahead）：64个page组成一个extend，如果当前extend当中的多个页被加载到内存当中，那么就将剩余的页也加载到
       内存当中。
```
14. char和varchar的区别？
```
    1. char是固定长度的，当varchar是变长的。
    2. char(50)表示这个变量占有50个字节。而varchar(50)表示这个变量最多可以占50个字节，最少可以占0个字节。
```

15. InnoDB 日志种类，事务是如何通过日志实现的？
```
    1. 日志种类
        1.1 错误日志：记录错误信息，也记录一些警告和查询信息。
        1.2 查询日志：记录所有対数据库请求的信息，不论这些请求是否得到正确执行。
        1.3 慢查询日志：设置一个时间阈值，执行时间超过此时间的SQL语句都将被记录进来
        1.4 二进制日志：所有的写操作
        1.5 中继日志：部分写操作
    2. 四种事务级别
        2.1 读取未提交的内容：事务之间可以互相看到对方未提交的执行结果。
        2.2 读取已提交的内容：事务之间只能看到对方已提交的结果。
        2.3 可重复读：同一事务的不同实例在并发访问时会看到同样的数据行。可能会导致“幻读”。MySQL默认级别。
            A实例在读0-10行的数据，B实例向0-10行中插入新的行，A实例再次读，发现和上次不一样。这就是“幻读”。
        2.4 可串行化：事务之间都是排序的。在每个数据行上面加上共享锁。所以效率很低。
    3. 事务实现方式：
        3.1 通过redo和InnoDB的日志缓冲实现的。
```
16. MySQL数据库CPU飚到500%怎么处理？
```
    1. show processlist; 观察CPU最高，时间最长的进程，并关掉。
```
17. SQL 优化
```
    1. explain出来的各种item含义
        1.1 select_type: select字句的类型。
        1.2 table: 操作的表
        1.3 type: 访问类型
        1.4 possible_keys: 可以用的索引
        1.5 key: 实际使用的索引
        1.6 key_len: 索引中使用的字节数
        1.7 ref: 表的连接匹配条件
        1.8 extra: 不再其它列中，但是比较重要的信息
        1.9 partition: 分区信息
    2. profile 的意义
        2.1 查询SQL语句执行了多长时间。
        2.2 查询SQL语句占用的CPU和内存。
```
18. MySQL索引的最左前缀原则？
```
    1. 有一个复合索引index(a, b, c)
    where a = 1 and b = 2; 能用上。
    where a = 1 and c = 3; 能用上a
    where b = 2 and c = 1; 不能用上。
```
19. MySQL主从服务器，主服务器是InnoDB，从服务器是MyISAM，应用会遇到什么问题？
```
    1. MyISAM是表级锁，在同步的时候，无法提供读服务。
    2. MyISAM不支持事务，突然宕机会导致数据丢失。
```
20. MySQL语句应该考虑哪些安全性？
```
    1. 防止SQL注入，対特殊字符进行转义，使用预编译sql语句绑定。
    2. 使用最小权限原则，为不同动作建立不同的账户。
    3. sql出错时，不要把数据库的出错信息暴露给客户端。
```
21. MySQL有哪些索引类型？
```
    1. 普通索引：可重复
    2. 唯一索引：不可重复
    3. 主键索引：不为空
    4. 全文索引：like %word%
    5. 复合索引：index(A,B,C),最左前缀匹配
    6. 外键索引
```
22. MySQL中的乐观锁和悲观锁？
```
    1. 乐观锁：它实际上并不是锁，一般用CAS（Check And Set）来实现。给数据库增加一个版本或时间戳字段。
       在读行数据的时候，需要读取这个版本字段。在写数据的时候要比较之前取数据的时候的版本号与现在的版本号
       是否相等，相等就可以写入；否则，拒绝写入。
    2. 悲观锁：它就是一把锁。在访问行数据的时候，会给这一行加上一把锁，访问结束后，取下这把锁。
```
23. MySQL主键，超键，候选键，外键？
```
    1. 主键：可以唯一表示行数据的列元组，不可以有空值，也不可以重复。
    2. 候选键：可以唯一标识行数据的列元组，不存在冗余列。
    3. 超键：存在冗余列。
    4. 外键：另一个的主键。
```
24. MySQL 视图的作用，视图可以更新吗？
```
    1. 虚拟的表，不包含数据。
    2. 用来保护数据，简化检索。
    3. 大部分视图不可以更新。
```
25. MySQL 数据库范式
```
    1. 第一范式：每一列都不可以被分割，没有重复的列。不足第一范式就不是关系型数据库。
    2. 第二范式：非主属性完全依赖主属性。
    3. 第三范式：非主属性不依赖于其它非主属性。
```
26. MySQL 数据库优化的思路？
```
    1. 语句优化
        1.1 where 子句中尽量避免 <>, ！=， 否则会退化成全表扫描。
        1.2 where 子句中尽量避免null判断，否则会退化成全表扫描。可在numer的null值上设置为0.
        1.3 使用 exist 比 in更好。
        1.4 where子句代替having。因为having只会在数据被查询出来后才对结果进行过滤。
    2. 索引优化
        2.1 经常搜索的列上建索引。
        2.2 主键的列上建索引。
        2.3 order by 子句上的列建索引。
        2.4 where 子句上的列建索引。
        2.5 查询中很少使用的列上不要建索引。
        2.6 只有很少数据值的列上也不要建索引。
        2.7 text，blob类型的列上不要建索引。
        2.8 索引的代价：
            2.8.1 占据而外的空间
            2.8.2 更新索引需要花时间
    3. 数据库结构优化
        3.1 范式优化
        3.2 反范式优化，适当增加冗余，减少join的使用
        3.3 表的拆分。
```
27. MySQL 触发器
```
    1. 六种，before/after update/delete/insert.
```


算法：
1. 基本排序中，哪些是稳定的，哪些是不稳定的？
```
    1. 稳定排序：冒泡排序，插入排序 ，归并排序，基数排序
    2. 不稳定排序：选择排序，快速排序，希尔排序，堆排序
```
2. 如何对一个20GB的大文件进行排序？
```
    1. 采用外归并排序，假设机器的内存为100M，要对900M的数据进行排序
    2. 依次读入100M的数据到内存中，采用某种常规方式（快速排序，堆排序等）在内存中完成排序
    3. 处理完成后，会产生9个100M的有序的临时文件，位于磁盘上
    4. 读取每个文件的前10M到内存，共占用90M。最后的10M用作输出缓冲区。
    5. 执行9路归并排序，将结果写入道输出缓冲区，一旦输出缓冲区满了，就将缓冲区的数据写入到磁盘上，清空缓冲区。
    6. 当9个输入缓冲区有一个变空时，就从这个缓冲区对应的文件中读取下一个10M文件，除非这个文件已经读取完了。
```
3. 如何判断两个无环单链表是否有交叉点？
```
    1. 分别遍历两个链表，若最后一个节点的值相等，则有交叉点；反之，没有。
```
4. 如何判断一个单链表有没有环，并找出交叉点？
```
    1. 分别创建两个指针指向链表的头节点，第一个指针每次走1步，第二个指针每次走2步。看看是否会有指向相同元素的时刻。
    2. 如果存在指向相同元素，则有环；反之，无环
```
5. 手写一个快速排序？
```

func partition(A []int, lo, hi int) int  {
	pivot := A[hi]
	i := lo
	for j:=lo; j<=hi; j++ {
		if A[j] < pivot {
			A[i], A[j] = A[j], A[i]
			i ++
		}
	}
	A[i], A[hi] = A[hi], A[i]
	return i
}

func quickSort(A []int, lo, hi int) {
	if lo < hi {
		p := partition(A, lo, hi)
		quickSort(A, lo, p-1)
		quickSort(A, p+1, hi)
	}
	
}

```
6. 给一个二叉树，判断是否是二叉搜索树？
```
func isValidBST(root *TreeNode) bool {
	return helper(root, nil, nil)
}


// helper ...
func helper(root, min, max *TreeNode) bool {
	if root == nil {
		return true
	}

	if min != nil && min.Val >= root.Val {
		return false
	}

	if max != nil && max.Val <= root.Val {
		return false
	}

	return helper(root.Left, min, root) &&
		helper(root.Right, root, max)
}
```

中间件
1. 介绍一下消息中间件 kafka
```
    1. 为啥要是用消息队列？
        1.1 解藕：消息的生产和消费是两个独立的部分，方便程序修改
        1.2 异步通信：生产者只负责生产，消费者只负责消费，两者速率可以有差别。从而提高系统的运行效率。
        1.3 削峰：比如秒杀活动，避免系统被突发流量弄崩溃
        1.4 顺序保证：消息消费的顺序就是生产的顺序
        1.5 送达保证：只有得到消费者已经消费掉这个消息后，才会将这个消息删除；否则，一直会存在。
    2. kafka中的名词解释
        2.1 broker: 代理商，kafka集群包含1个到多个服务器，每个服务器被称为一个broker
        2.2 topic：主题，每个消息都有一个主题
        2.3 partition：物理分区，消息实际存放的地方。每个partition对应一个文件夹，包含索引和日志信息
        2.4 producer：生产者，向broker发送消息的对象
        2.5 consumer: 消费者，从broker读取消息的对象。多个消费者可以构成一个消费者组。不同消费者组里的成员可以消费
            同一个分区，但是同一消费者组里的成员不能消费同一分区。
    3. 分区的选择方式
        3.1 如果消息没有key，那么采用轮询的方式选择分区。
        3.2 如果消息有key，那么取hash(key)%partition_num的值来选择分区
        3.3 注意，同一分区内的消息是有序的，但是不同分区的数据不是有序的。
        3.4 分区删除旧消息的方式：
            3.4.1 时间方式：默认7天
            3.4.2 大小方式：默认1GB
            3.4.5 检查间隔：默认每5分钟检查一次
    4. Leader 和 Follower 复制
        4.1 Leader 完全负责读和写，Followers仅仅复制，在Leader挂掉之后选取出新的Leader
        4.2 ISR(In Sync List): 如果一个Follower落后太多（时间或者消息数量上），就将它从ISR队列中移除。
        4.3 消费者可以指定消息送达的可靠性：发送消息后不需要获得broker的应答，或者仅仅Leader的应答，或者所有Follower的应答
    5. Consumer Rebanlance 消费者重新平衡是由Zookeeper管理的。
    6. 如何在分区中找到对应的offset
        6.1 通过offset从索引文件中找到最近的索引
        6.2 利用该索引值在日志文件中结合offset顺序查找，直到找到消息
        6.3 使用稀疏索引的方式，减少了索引文件的大小。
```