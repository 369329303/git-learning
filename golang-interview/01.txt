golang 语言部分

1. golang的堆内存管理？
```
    1. 采用TCMalloc的分配方式，核心理念是使用多级缓存，根据对象大小分类，并按照类别实施不同的分配策略。
    2. 对象大小：
        微对象：(0, 16B)
        小对象：[16B, 32KB]
        大对象：(32KB, ...)
      程序中的对象大部分都在32KB以下，而分配内存的大小影响Go语言分配时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。
    3. TCMalloc和Go引入线程缓存(Thread Cache)，中心缓存(Central Cache)和页堆(Page Heap)三个组件来分级管理内存。
       线程缓存属于每一个独立的处理器P，它能够满足绝大多数的内存分配需求，因为不涉及多线程，所以也不需要互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。
       当线程缓存不能够满足需求时，就会使用中心缓存作为补充解决小对象的内存分配问题；当遇到32KB以上的对象时，内存分配器就会选择页堆直接分配大量的内存。
    4. 使用稀疏内存布局，移出了线性内存布局下堆大小的上线，还解决了C和Go混合使用时地址空间冲突问题。
    5. 每一个P都会被分配一个线程缓存 runtime.mcache 用于处理微对象和小对象的分配，它们持有内存管理单元 runtime.mspan.
       每个内存管理单元都会管理特定大小的对象，当内存管理单元不存在空闲对象时，就会从 runtime.mheap 持有的 134 个中心缓存 runtime.mcentral 中获取新的内存单元。
       中心缓存从属于全局的堆结构体 runtime.mheap，他会从操作系统中申请内存。
       Go语言的内存管理模块一共包含67种跨度类，每一个跨度类都会存储特定大小的对象，并且包含特定数量的页数.
       跨度类除了存储类别的ID之外，还会存储一个noscan标志位，该标志位表示对象是否包含指针，GC只会対包含指针的 runtime.mspan 进行扫描
    6. 线程缓存：runtime.mcache 是Go中的线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。每一个线程缓存都持有67*2个runtime.mspan
    7. 中心缓存：runtime.mcentral 是Go中的中心缓存，与线程缓存不同，访问中心缓存的内存管理单元需要使用互斥锁。
       每一个中心缓存都会管理某个跨度类的内存管理单元，它会同时持有两个 runtime.mSpanList 分别存储包含空闲对象和不包含空闲对象的链表
    8. 页堆：runtime.mheap 是内存分配的核心结构体，堆上存在的所有对象都是由该结构体进行管理的。它包含两个非常重要的字段，一个是全局的中心缓存列表 central， 另一个是
       管理堆区内存区域的arenas。
       页堆中包含一个长度为134的 runtime.mcentral 数组，其中 67 个为需要 scan 的中心缓存，67个为不需要 scan 的中心缓存。
```

2. golang的垃圾回收机制？
```
    1. Sweep Termination: 清扫终止阶段。如果当前程序是强制触发的，我们还需要处理未被清理的内存管理单元。
    2. Mark：标记阶段。
        2.1 开启STW,写屏障，用户程序协助，并将根对象入队。
        2.2 关闭STW，恢复用户程序，标记进程和协助进程开始标记内存中的对象，写屏障会将修改的指针标记为灰色，而新创建的指针会被标记为黑色。
        2.3 扫描根对象，包括所有Goroutine的栈，全局对象。扫描Groutine的栈期间，暂停当前处理器。
        2.4 依次处理灰色队列中的对象，将对象标记为黑色，并将它们指向的对象标记为灰色。
        2.5 检查灰色队列是否为空，不为空则继续标记，否则进入标记终止阶段
    3. Mark Termination: 标记终止阶段，开启STW，暂停程序，关闭写屏障和用户程序协助，恢复用户程序
    4. Sweep：清理阶段
        4.1 所有新创建的对象都会被标记为白色
        4.2 后台并发清理内存

    5. 触发时机：
        5.1 堆目标：分配的内存翻了一倍
        5.2 时间目标：每隔2min
        5.3 手动触发：runtime.GC()
    6. 虽然指针比值传参数所消耗内存要小，但是会增加垃圾回收器的负担。所以如果对象比较小的话，应该使用值传参。
```
3. golang是如何调度Goroutine的？
```
    1. 线程是通过共享内存进行通信的（比如说锁），而Goroutine可以通过通信来共享内存（利用channel）
    2. Go 语言的调度器通过使用与CPU数量相等的线程减少线程频繁切换的开销，同时在每一个线程上执行开销更低的Goroutine来降低对于操作系统和硬件的负载。
    3. 单线程调度器(0.x)，多线程调度器(1.0)，任务窃取调度器(1.1)，抢占式调度器(1.2-至今)，非均匀存储访问调度器(提案)
    4. 任务窃取调度器：G-M-P模型
        4.1 G-M-P模型中引入的处理器P是线程和Goroutine的中间层，处理器持有一个由可运行的Goroutine组成的运行队列 runq，还反向持有一个线程。
            调度器调度时，会从处理器的runq队列中选择队列头的Goroutine放到线程M上。
        4.2 基于工作窃取的多线程调度器将每一个线程绑定到了独立的CPU上，这些线程会被不同的处理器管理，不同的处理器通过工作窃取实现任务再分配
    5. 抢占式调度：
        5.1 在之前的1.1版本中，为非抢占式调度。程序只能够依靠Goroutine主动让出CPU资源才能触发调度。存在以下问题：
            5.1.1 某些Goroutine可以长时间的占用线程，造成对应P的runq中其它Goroutine的饥饿
            5.1.2 GC的STW阶段耗时太长
        5.2 基于协作的抢占式调度：通过编译器插入函数实现
            5.2.1 Go 语言运行时会在GC时暂停程序，系统监控Goroutine，运行超过10ms发出抢占请求 StackPreempt
            5.2.2 当发生函数调用时，可能会执行编译器插入的 runtime.morestack 函数，它调用的 runtime.newstack 会检查Goroutine的 stackguard0 字段是否为
                  StackPreempt;
            5.2.3 如果 stackguard0 是 StackPreempt，就会触发抢占让出当前P。
        5.3 基于信号的抢占式调度：还有一些问题没有解决
    6. 数据结构
        6.1 G - Goroutine，表示一个待执行的任务
                type g struct {
                    stack       stack   // 描述当前Goroutine的栈内存范围[stack.lo, stack.hi)
                    stackguard0 uintptr // 用于抢占式调度
                    _panic      *_panic
                    _defer      *_defer
                }
        6.2 M - 操作系统线程，由操作系统的调度器调度和管理
            6.2.1 调度器最多可以创建10000个线程，但是最多只会有GOMAXPROCS个活跃线程能够同时正常运行
            6.2.2 g0 是持有调度栈的Goroutine，curg 是在当前线程上运行的用户Goroutine
                type m struct {
                    g0 *g
                    curg *g 
                    ...
                }
        6.3 P - 处理器，可以被看作是运行在线程上的本地调度器
            6.3.1 提供线程需要的上下文环境，负责调度所持有的等待队列
    7 全局和本地运行队列
        7.1 Go语言中有两个运行队列，其中一个是处理器的本地运行队列，另一个是调度器持有的全局运行队列，只有在本地运行队列没有剩余
            空间（最多可以存储256个待执行Goroutine，它是一个环形队列）时才会使用全局队列。
        7.2 公平层次
            Goroutine - 抢占式
            本地运行队列 - 时间片 10ms
            全局运行队列 - 通过 schedtick%61 保证有一定概率选择一个
            网络轮询器 - 后台线程检查网络准备状态是否就绪
            随机从其它处理器的runq中窃取一部分Goroutine

            1. globrunqget(_g_.m.p.ptr(), 1)  // schedtick % 61
            2. runqget(_g_.m.p_ptr())   // runnext
            3. findRunnable() // 阻塞
                3.1 runqget(_p_)    // 本地队列中取一个
                3.2 globrunqget(_p_, 0) // 从全局队列中取出一部分
                3.3 netpoll(0)      // 就绪态的网络连接中取出一个
                3.4 runqsteal(_p_, p2, strealRunNextG)  // 从其它本地队列中偷一半
    8 调度触发条件
        8.1 当前Goroutine主动挂起
        8.2 系统调用
        8.2 协作式调度
        8.3 系统监控

```
4. golang是如何进行并发控制的？
```
    1. 全局变量
    2. channel 和 sync.WaitGroup
    3. context包
        3.1 context.Context 是用来设置截止时间，同步信号，传递相关值的接口
        3.2 context.Context 定义了四个需要实现的方法
            type Context interface {
                Deadline() (deadline time.Time, ok bool)    // 返回context.Context 被取消的时间
                Done() <-chan struct{}  // 返回一个channel,这个channel会在当前工作完成或者上下文被取消之后关闭，多次调用Done方法会返回同一个channel
                Err() error // 返回结束的原因。被取消：返回Canceled错误；超时：返回 DeadlineExceeded错误         
                Value(key interface{}) interface{}  // 获取建对应的值，用来传递数据
            }
        3.3 在Goroutine构成的树形结构中対信号进行同步以减少计算资源的浪费是context.Context的最大作用。
```
5. golang中的slice类型介绍一下？扩容机制？
```
    1. 在编译期确定切片内元素类型
    2. 数据结构
        type SliceHeader struct {
            Data uintptr
            Len int
            Cap int
        }

        type stringStruct struct { // 这是string的结构体，与slice相像，由于string不存在扩容，所有没有cap字段。
	        str unsafe.Pointer
	        len int
        }
    3. 当切片非常大或者发生逃逸时，会被分配在堆上
    4. 扩容策略
        4.1 如果期望容量大于当前容量的两倍，直接使用期望容量
        4.2 如果当前容量小于1024，容量翻倍
        4.3 如果当前容量大于1024就会每次增加25%的容量，直到新容量大于期望容量
```
6. golang中的defer关键字介绍一下？
```
    1. defer 传入的函数不是在退出代码块的作用域时执行的，它只会在当前函数或方法返回前被调用。
    2. deder 会对函数参数进行预计算
    3. defer 在编译器看来也是函数调用
    4. 遇到defer 关键字的时候，会创建一个 _defer 数据结构(会对函数参数进行预计算)，但是还没有加入到 defer 链上，在栈搭建完成之后，会从栈顶向栈底扫描defer结构，
       逐个添加到defer链中。在函数返回时，会判断defer链是否为空。如果不为空，就依次从链头defer执行到链尾defer；否则，直接退出函数。
```
7. golang中的接口？
```
    1. 接口的实现都是隐式的
    2. interface{} 类型不是任意类型
        eface结构体表示不包含任何方法的结构体,iface结构体表示包含方法的结构体.
        type eface struct {
            _type *_type    // 存储运行时类型
            data  unsafe.Pointer
        }

        type iface struct {
            tab *itab       // itab结构体内部含有_type结构体。
            data unsafe.Pointerk
        }
    3. 指针类型的方法是无法被结构体类型对象调用的。
    4. 类型断言：
        4.1 对于eface 来说，通过比较eface._type.hash 与 目标类型的 hash 进行比较
        4.2 对于iface 来说，通过比较iface.tab.hash 与 目标类型的 hash 进行比较
    5. 使用结构体来实现接口的开销会大于使用指针实现，动态派发(Dynamic Dispatch)在结构体上的表现非常差
```
8. gRPC框架 是什么？
```
grpc是一个由Google开源的，高性能，支持多语言的RPC框架。基于HTTP/2协议设计，单TCP连接上多个双向Stream，头部压缩功能。
调用模型：
    1. 客户端调用方法A，发起RPC调用
    2. 对请求信息使用protobuf对数据进行序列化，通过http/2协议通信
    3. 服务端收到请求后，反序列化，获得请求，执行业务逻辑处理并返回应答
    4. 对应答信息使用protobuf再次序列化然后发给客户端
调用方式：
    1. 一元RPC
        invoke()
        客户端创建grpc的时候，就已经将数据发送过去，并阻塞等待数据到来。
    2. 服务端流式RPC
        客户端创建grpc
                        Send(主动关闭)
        Recv
    3. 客户端流式RPC
        客户端创建grpc
        Send
                        Recv
        CloseAndRecv(阻塞，直到收到消息，主动关闭)
                        SendAndClose
    4. 双向流式RPC
        go Recv
        Send
                        Recv
                        Send
        SendClose（主动关闭）
常见问题：
    1. grpc.Dial 是异步连接，状态为正在连接，但如果设置了grpc.WithBlock选项，就会阻塞等待直到连接建立。
    2. 调用ClientConn不Close会导致文件句柄过多，内存泄漏
    3. 如果不进行超时控制的话，短时间内不会有问题，但如果时间长了，就会造成文件句柄过多，内存泄漏
    4. 默认的拦截器可以传递多个，但是只有第一个有用。
    5. 频繁创建ClientConn会造成占用过多的文件句柄。对于需要大量创建，大量销毁的情形（比如http连接），可以考虑用一个Goroutine池。
    6. 客户端请求失败会重试，直到上下文取消，重试时间采用backoff算法，最大重试时间为120s。
    7. gRPC基于HTTP/2协议，附加信息都会放在HEADERS帧中，数据放在DATA帧中
```
9. Go 中map的实现原理？
```
    1. 采用桶装法（类似一个中间层，与redis的map类似）
        type hmap struct {
            count     int       // 当前哈希表中的元素个数（包括正常桶和溢出桶）
            flags     uint8
            B         uint8     // 当前哈希表持有的正常buckets数量的log值，len(buckets) == 2 ^ B 
            noverflow uint16    // 溢出桶的数量
            hash0     uint32    // 哈希的种子，为哈希函数的结构引入随机性，在创建哈希表的时候确定

            buckets    unsafe.Pointer   // 保存正常桶的基地址
            oldbuckets unsafe.Pointer   // 哈希在扩容时用于保存旧正常桶的基地址
            nevacuate  uintptr          // 哈希表在扩容时，已经迁移到新桶的元素数量

            extra *mapextra             // 包含了溢出桶的基地址，正常桶和溢出桶在开始分配的时候是连续的，
                                        // 但是之后由于溢出桶的元素逐渐增多，溢出桶会迁移到新的地址，从而两者之间就会不连续了。
        }

        // 每个桶内只装有8个元素，超出的元素放在溢出桶内，若对应溢出桶已满，则继续添加溢出桶
        type bmap struct {      // 桶的结构体，编译期间重构的结果
            topbits  [8]uint8   // 每个桶中存储8个键值対，存储了键的哈希值的高8位
            keys     [8]keytype
            values   [8]valuetype
            pad      uintptr    // 不确定是否一定会有这个字段？
            overflow uintptr    // 下一个溢出桶的地址
        }
        如果哈希表中存储的元素主键增多，会使用溢出桶或者扩容
    2. 读操作
        v     := hash[key] // => v     := *mapaccess1(maptype, hash, &key)
        v, ok := hash[key] // => v, ok := mapaccess2(maptype, hash, &key)
        在编译期根据左边变量的个数来确定使用那种方法。
    3. 扩容策略
        3.1 触发条件
            3.1.1 装载因子超过6.5，存储的所有元素数量/正常桶的数量
            3.1.2 使用了太多的溢出桶
        3.2 扩容不是一个原子过程，是一个增量过程，不会造成性能的巨大抖动。读操作不会触发扩容，写操作会触发扩容。
```
10. set实现一下？
11. Go 的栈内存管理？
```
    1. i386 和 x86_64架构的机器上，默认的线程栈大小是2MB。而Goroutine的栈大小最小为2KB，可以动态调整，最大达到1GB。
    2. 逃逸分析
        2.1 逃逸分析是用来决定指针的动态作用域，会不会超过当前栈。Go语言编译器使用逃逸分析来决定哪些变量应该在栈上分配，哪些应该在堆上分配。
        2.2 两个不变性：
            2.2.1 指向栈对象的指针不能够存在于堆中
            2.2.2 指向栈对象的指针不能够在在对象被回收后存活
        2.3 使用 go build --gcflags="-m -m" 来确定变量到底是分配在了哪里。
        2.4 一般函数返回的指针变量和非常大的变量会分配在堆上。
    3. 栈的动态扩容是通过栈分裂和栈增长实现的。
    4. 对于<32KB 的对象，per M cache来分配，避免锁竞争；>=32KB的对象，从全局栈中分配，还不够就从堆分配。

```
12. Go 的同步原语与锁
```
    1. 基本原语：sync.Mutex, sync.RWMutex, sync.WaitGroup, sync.Once, sync.Cond.
    2. 互斥锁，任意时刻只能被一个Goroutine所持有。
    3. 读写锁，可以并发读，但是不能并发写或者读写。
    4. sync.WaitGroup 等待一组Goroutine的返回，常用场景如批量发出RPC或HTTP请求
    5. sync.Once 保证Go程序运行期间的某段代码只会执行一次。
        5.1 使用了互斥锁和sync/atomic包提供的方法Load/Store.
        5.2 两次调用sync.Once.Do方法传入不同的函数也只会执行第一次传入的函数
    6. sync.Cond 不常用。
        6.1 sync.Cond.Wait 方法在调用之前一定要先获取互斥锁，否则程序会崩溃，不能unlock一把已经unlocked的锁
        6.2 sync.Cond.Signal 方法唤醒的Goroutine是等待队列最前面的Gouroutine
        6.3 sycn.Cond.Broadcast 会唤醒所有的Goroutine
```
13. Go 的网络轮询器
```
    1. 网络轮询器用于监控网络IO和文件IO。
    2. 阻塞IO：最常见的IO模型，対文件和网络的读写操作默认情况下，都是阻塞的。当执行read系统调用时，应用程序从用户态陷入内核态，直到文件描述符
       中的数据准备好之后，才会返回用户态。
    3. 非阻塞IO：当执行read系统调用时，应用程序会不断的向操作系统询问数据是否已经准备好了，准备好了之后就会从内核态中取回数据。在等待过程中，CPU
       可以执行其它任务。
    4. IO多路复用：用来处理同一事件中的多个IO事件。多路复用函数(select)会阻塞地监听一组文件描述符，当文件描述符转变为可读或可写后，
       select 会返回可读或者可写事件的个数，应用程序就可以在输入的文件描述符中，查找哪些可读或者可写，然后执行相应操作。
```

14. Go 系统监控
```
    1 检查死锁
    2 运行计时器： 获取下一个需要被触发的计时器
    3 轮询网络：获取需要处理的到期文件描述符
    4 抢占处理器：抢占运行时间较长的或者处于系统调用的Goroutine
    5 垃圾回收：在满足条件时触发垃圾回收机制
```
15. Go 函数调用 
```
    1. 通过堆栈传递参数，入栈的顺序是从右到左
    2. 调用函数是都是传值。
    3. 数组在进行参数传递的时候，实际上会拷贝一整份数组，但是在for-range的时候却不是拷贝，因此建议不要使用数组。不过数组倒是可以很方便的实现环形队列。
```

16. for 和 range
```
    1. 可以快速遍历数组，切片，哈希表以及channel等集合类型
    2. range循环中，Go语言会在编译期将原切片或者数组赋值给一个新的变量ha，在赋值的过程中发生了拷贝，
       我们遍历的切片变量已经不是原来的切片变量了。
        ha := a
        hv1 := 0
        hn := len(ha)
        v1 := hv1
        for ; hv1 < hn; hv1++ {
            tmp := ha[hv1]
            v1, v2 := hv1, tmp
            ...
        }
```

17. Go 语言中 new 和 make的区别
```
    1. make的作用是用来初始化内置的数据结构，包括slice, map, channel
    2. new 的作用是根据传入的类型分配一块内存空间并返回指向这块内存空间的指针
```

操作系统部分：
1. 死锁产生的四个必要条件及如何避免死锁？
```
    1. 互斥条件：一个资源只能被一个进程所占有
    2. 占有并等待：一个进程因请求新的资源不满足而阻塞时，対已经获得的资源不释放
    3. 不可强行占有：一个进程的资源只能主动释放，不能被动释放。
    4. 循环等待条件：若干进程间形成循环等待的关系
```
2. 进程，线程，协程的区别？
```
    1. 进程是资源分配的基本单位，进程间通信通过IPC来通信
    2. 线程是CPU调度的基本单位，同一进程内的多个线程共享所属进程的资源。拥有自己的栈，程序计数器。进程间通信通过共享内存。
    3. 协程位于用户态，用户态程序负责调度，拥有自己的栈，程序计数器。可以通过channel来共享内存。更加安全，方便。
```
3. LVS有哪几种模式？各有什么特点？
```
    3.1 NAT 模式：RS和DS位于同一个网段内，DS是RS的网关。请求和回答都得经过DS，DS是系统瓶颈。使用了DNAT，类似于透明代理。
    3.2 TUN 模式：RS和DS通过IP管道来进行传输，可以不在同一个局域网内，有利于异地容灾。请求经过DS，但应答不经过DS。由于使用了管道增加了数据量。
    3.3 DR 模式（Direct Routing 直接路由）： RS和DS位于同一个网段内，通过修改MAC地址来进行DS到多个RS的路由。请求经过DS，但应答不经过DS。目前应用的最多。
```
4. Keepalived介绍一下？
```
    4.1 VRRP 虚拟路由冗余协议：将多个路由器设备虚拟成一个设备，对外提供一个或多个虚拟IP地址。这些路由器设备中只有一个是master，其余都是slave。
        master会定时向slave发送VRRP通告信息，表明自己还活着。如果一段时间内没有收到，slave之间会通过VRRP通告来选取出一个新的master。
    4.2 VRRP数据包的目标IP地址必须是224.0.0.18（广播地址）.
    4.3 keepalived程序有三个进程。其中父进程负责内存管理。子进程1负责VRRP协议的实现，负责master/slave的切换。子进程2负责健康检查，如HTTP服务器是否存活。
    4.4 虚拟IP的出现是根据master/slave的状态确定的。master上的虚拟IP出现在非lo网卡上，而slave上的虚拟IP出现在lo网卡上。
```

网络方面：
1. select, poll, epoll 之间的区别在哪里？
```
    1. select，时间复杂度O(n),监听一组描述符，仅仅知道有事件发生了，但并不知道具体是哪些文件描述符，只能够遍历。
    2. poll，与select类似，时间复杂度O(n),区别仅在于没有了文件描述符数量的限制，因为是基于链表来存储的。
    3. epoll, 时间复杂度O(1)，当epoll返回时，我们知道是哪些文件描述符准备好了，每个事件上都关联着文件描述符。
        包括LT（Level Trigger）和ET（Edge Trigger）。
        LT模式下，只要这个事件没有处理，每次都会返回这个事件。
        ET模式下，仅仅只会返回一次
        select和poll中，所有的文件描述符都会在内核态和用户态之间复制多次，造成浪费。而epoll并不需要，只需返回就绪态的文件描述符。
```
2. HTTP/1.1 于 HTTP/2 的区别？
```
    1. HTTP/1.1 是1999年提出的，HTTP/2 是2015年提出的。
    2. 影响HTTP网络请求的因素主要有两个，带宽和延迟。现在已经不是拨号上网的年待了，所以带宽不再是一个因素；延迟，DNS查询可以通过DNS缓存来解决。Head Of Line 阻塞，一个连接上无法跑多个请求都是问题。
    3. 多路复用：HTTP/1.1的pipeline(keep-alive)机制虽然可以在一个TCP连接上跑多个请求，但是无法并发，容易产生HOL阻塞。
        而HTTP/2的多路复用是将请求分散，当作流来处理，每个请求对应不同的流，实现了请求的并发，并不会造成HOL阻塞。
    4. 首部压缩 ：HTTP/1.1的首部是不压缩的，并且多个请求通常都包含相同的首部。这对于带宽和延迟都很浪费。而HTTP/2通过在客户端和服务端分别维护一个动态字典和一个静态字典，用字符代替请求头来传输，降低带宽和延迟。
    5. 服务器推送：HTTP/1.1中客户端请求main.html，服务端仅返回main.html,但是HTTP/2会同时返回main.html, main.css等。这样客户端下次请求main.css的时候直接在缓存中就可以找到了。
    6. 可以传递二进制信息
```
3. TCP共有哪些状态？
```
    closed      listen
 
    syn_send   
                syn_recv
    established 
                established
           ========
    fin-wait-1
                close-wait
    fin-wait-2  
                last-ack
    time-wait    

    此外closing 状态比较少见，属于同时发送FIN包的情况。之后只要同时收到对方发来的ACK包，就可以进入time-wait状态.
```

4. TCP握手和挥手的过程说一下？
```
    握手过程：
    ->    syn(SYN=x)
    <-    syn+ack(SYN=y, ACK=x+1)
    ->    ack(ACK=y+1)

    挥手过程：
    ->    fin(SYN=x)
    <-    ack(ACK=x+1)
    <-    fin(SYN=y)
    ->    ack(ACK=y+1)    

```
5. HTTP的状态码有那些？301和302的区别？401和403的区别？502和504的区别？
```
    1xx:
        100: 继续
        101: 切换协议（比如websocket）
    
    2xx：
        200: 成功
        206: 部分信息
    3xx：
        301: 永久移动
        302：临时移动
        304: 文件未修改
        307: 和302相同，但是会使用get来代替post
    4xx：
        400: 请求方法或参数不正确
        401: 未认证
        403: 权限不够
        404: 未找到
    5xx：
        500: 服务器内部错误
        502: 服务器作为网关或代理，从上游服务器收到无效应答
        504: 服务器作为网关或代理，从上游服务器接收应答超时
        505: 请求的HTTP协议版本不支持

```

6. Cookie和Session的区别？
```
    Cookie：服务器在客户端上存储的小段文本，并随着每一个请求发送至同一个服务器。cookie的内容包括名，值，过期时间，路径和域。默认过期时间是浏览器会话期间。
    Session：服务器利用散列表来保存Session信息。
    区别：
        1. 都是保存用户状态的技术
        2. Cookie一般用来存放ASCII，而Session可以用来存放二进制信息。
        3. 隐私策略不同：Cookie存放在客户端，客户端的某些程序能够读和写Cookie；而Session放在服务端，对于客户端是透明的，更加安全。
        4. 服务器压力不同：如果用户量特别多的化， 会给服务器增加负担。
        5. Session既可以通过在URL中添加SessionID的方式实现，也可以通过在Cookie中添加SessionID这一项。
        6. 单个Cookie在客户端的限制是3K，而Session没有限制。

```
7. TCP和UDP的区别？
```
    1. TCP是有状态的，UDP没有状态
    2. TCP是可靠的，UDP不可靠
    3. TCP报文比较大，UDP比较小
    4. TCP是面向字节流的，UDP是面向报文的。
    5. 还有一个SCTP (Stream Control Transmission Protocol), 被称为TCPng, 不过目前支持的平台比较少。能够解决TCP Head of Line Blcok 问题。
        允许在一个SCTP连接中跑多个流。LTE使用的就是这个协议。
```
8. TIME-WAIT的作用？
```
    1. 保证对方能够收到ACK报文，正确断开连接
    2. 避免新老连接混在一起，影响新连接的建立。
```
9. CLOSE-WAIT太多怎么办？
```
    1. 查代码，实现有问题。FIN包没有发送出去，可能是由于socket没有正常关闭。
```
10. 输入 ping IP 后，在发包之前会发生什么？
```
    1. 查询路由表，决定从哪个网卡出去。
    2. 判断是否在局域网内
        2.1 如果在局域网内，查询arp表，如果查到了，直接发出去；否则向局域网内发arp广播查询该IP地址对应的MAC地址，查到后缓存该IP-MAC対，并发出去。
        2.2 如果不在局域网内，填入网关的MAC地址让网关转发出去。
```
11. 建立一个socket要经过哪些步骤？
```
    1. 服务器和客户端分别调用 int socket(int domain, int type, int protocol); 建立一个socket.
    2. 服务器和客户端分别调用 int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 将socket 绑定到本地的一个地址上面来。
    3. 服务器上用 int listen(int sockfd, int backlog); 开启socket监听,等待客户端的连接
    4. 客户端上用 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 连接服务器
    5. 服务器上用 int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 建立起一个socket连接
    6. 服务器和客户端分别调用 ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 来进行通信。
    7. 服务器和客户端均可以调用 int close(int fd); 来关闭连接
```
12. TLS的握手过程详细说一下？
```
    TLS1.2 完整握手过程：
      Client                                               Server

      ClientHello                  -------->
                                                      ServerHello
                                                     Certificate*
                                               ServerKeyExchange*
                                              CertificateRequest*
                                   <--------      ServerHelloDone
      Certificate*
      ClientKeyExchange
      CertificateVerify*
      [ChangeCipherSpec]
      Finished                     -------->
                                               [ChangeCipherSpec]
                                   <--------             Finished
      Application Data             <------->     Application Data

             Figure 1.  Message flow for a full handshake

    1. ClientHello 和 ServerHello 用来定义协议版本，Session ID， 算法套件，压缩方法，还有两个随机数。
    2. 密钥交换需要Server Certificate, ServerKeyExchange, Client Certificate, ClientKeyExchange四个消息。
    3. 第一个被加密的信息是Client Finished。
    4. SessionID 在ServerHello 中。
    5. DHE能够提供FS (Forward Secrey) 前向安全，DH,RSA不能够
    6. APLN存在ClientHello消息中，用来告诉服务器它所加密的上层协议类型。
    7. SNI存在ClientHello消息中，用来解决一个IP地址上多个域名的问题。
    8. Session重用通过Session ID和 Session Ticket的方式解决

    TLS1.2 恢复握手过程：
      Client                                                Server

      ClientHello                   -------->
                                                       ServerHello
                                                [ChangeCipherSpec]
                                    <--------             Finished
      [ChangeCipherSpec]
      Finished                      -------->
      Application Data              <------->     Application Data

          Figure 2.  Message flow for an abbreviated handshake
    
    1. ClientHello 中存放着之前的Session ID信息。
    2. 此时必须要发送ChangeCipherSpec消息


    TLS1.3 握手过程：
       Client                                           Server

Key  ^ ClientHello
Exch | + key_share*
     | + signature_algorithms*
     | + psk_key_exchange_modes*
     v + pre_shared_key*       -------->
                                                  ServerHello  ^ Key
                                                 + key_share*  | Exch
                                            + pre_shared_key*  v
                                        {EncryptedExtensions}  ^  Server
                                        {CertificateRequest*}  v  Params
                                               {Certificate*}  ^
                                         {CertificateVerify*}  | Auth
                                                   {Finished}  v
                               <--------  [Application Data*]
     ^ {Certificate*}
Auth | {CertificateVerify*}
     v {Finished}              -------->
       [Application Data]      <------->  [Application Data]

              +  Indicates noteworthy extensions sent in the
                 previously noted message.

              *  Indicates optional or situation-dependent
                 messages/extensions that are not always sent.

              {} Indicates messages protected using keys
                 derived from a [sender]_handshake_traffic_secret.

              [] Indicates messages protected using keys
                 derived from [sender]_application_traffic_secret_N.

               Figure 1: Message Flow for Full TLS Handshake



         Client                                               Server

         ClientHello
         + early_data
         + key_share*
         + psk_key_exchange_modes
         + pre_shared_key
         (Application Data*)     -------->
                                                         ServerHello
                                                    + pre_shared_key
                                                        + key_share*
                                               {EncryptedExtensions}
                                                       + early_data*
                                                          {Finished}
                                 <--------       [Application Data*]
         (EndOfEarlyData)
         {Finished}              -------->
         [Application Data]      <------->        [Application Data]

               Figure 4: Message Flow for a 0-RTT Handshake
    1. TLS1.2 需要2个rtt才能完成握手，TLS1.3只需要1个rtt就能完成握手。
    2. 移出了不安全的算法。只有DHE了。
    3. TLS1.2 需要1个rtt来完成Session重用，TLS1.3 的session重用只需要0个rtt
```

13. HTTP 的请求方式有那些，每个分别是什么意思？
```
    1. GET: 请求显示特定的资源，只用于数据读取，幂等操作
    2. POST：提交数据，如表单，文件。非幂等操作。
    3. HEAD：只获取响应头部，不获取响应主体。幂等。
    4. PUT：对已存在的资源更新。幂等。
    5. DELETE：删除指定资源。幂等。
    6. CONNECT：将服务器作为代理服务器连接
    7. OPTIONS: 探测服务器所支持的所有请求方法
    8. TRACE: 要求服务器回显其收到的信息
    9: PATCH: 若资源不存在，则创建；否则，更新。
```


数据库：
1. Redis的数据结构有哪几种，它们的底层实现是什么？
```
    1. string

        struct __attribute__ ((__packed__)) sdshdr8 {   // 可以存放2^8-1个字节
            uint8_t len; /* used */
            uint8_t alloc; /* excluding the header and null terminator */
            unsigned char flags; /* 3 lsb of type, 5 unused bits */
            char buf[];
        };


    2. list
        typedef struct listNode {   // list节点定义
            struct listNode *prev;  // 前指针
            struct listNode *next;  // 后指针
            void *value;    // 节点值
        } listNode;

        typedef struct listIter {   // 用于list遍历
            listNode *next;
            int direction;
        } listIter;

        typedef struct list {
            listNode *head;     // list 头
            listNode *tail;     // list 尾
            void *(*dup)(void *ptr);    // 用来复制节点的值
            void (*free)(void *ptr);    // 用来释放节点的值
            int (*match)(void *ptr, void *key); // 判断节点的值是否和key所指向的对象相等
            unsigned long len;  // list的长度
        } list;


    3. hash
        数量少用ziplist，数量多用dict。
        typedef struct dictEntry {
            void *key;
            union {
                void *val;
                uint64_t u64;
                int64_t s64;
                double d;
            } v;
            struct dictEntry *next;
        } dictEntry;


        typedef struct dictht {
            dictEntry **table;
            unsigned long size;     // dict的大小
            unsigned long sizemask;
            unsigned long used;     // dict中的元素数量
        } dictht;

        typedef struct dict {
            dictType *type;
            void *privdata;
            dictht ht[2];           // 两个dict，dict[0]日常使用，dict[1]仅仅在扩容的时候才会占有空间
            long rehashidx; /* rehashing not in progress if rehashidx == -1 */ // 在 <= rehashidx下，所有的旧桶都被迁移到了新桶
            unsigned long iterators; /* number of iterators currently running */    // 対dict进行扫描
        } dict;

        在扩容/缩容期间，scan的时候可能会扫描出重复的值。但是不会漏扫。
        在读/写的时候，如果处于rehash阶段，那么都会将旧桶中的元素分流到新桶中去。
        发生哈希碰撞时，新加入的元素放在链的前部，因为新数据接下来访问的概率更高。
    4. set
        对于set中的元素类型都是整型，并且数量较少时，采用intset来实现。否则采用dict来实现。
        对于dict来说，key是元素，value为null。
        inset 是有序的，可以使用二分查找。
        typedef struct intset {
            uint32_t encoding;  // 数据编码，2/4/8字节
            uint32_t length;    // inset 中元素的个数
            int8_t contents[];  // 柔性数组，数组的总长度length * encoding
        } intset;
        交集运算：
            1. 检查各个集合，一旦出现空集，立即停止运算，结果就是空集。
            2. 対各个集合按照数量从小到大来排序。更快的删除掉元素。
            3. 对于第一集合中的所有元素，只有当它在其余集合中均出现的时候才会被加入到目标集合
        并集运算：
            1. 遍历所有集合，将每个元素都加入到目标集合当中即可。
        差集运算：
            第一种算法：
                1. 対所有集合按照数量从大到小的顺序排序，有更大的概率查找到元素
                2. 遍历第一个集合中的所有元素，只有当此元素不存在于任何其它集合中时，才将此元素加入到目标集合中
            第二种算法：
                1. 将第一个集合中的所有元素放入到目标集合
                2. 遍历后面所有的集合，如果存在其余集合中，就从目标集合中删除此元素，最后的目标集合就是结果了。
    5. zset
        /* ZSETs use a specialized version of Skiplists */
        typedef struct zskiplistNode {      // skiplist 中的元素类型
            sds ele;    // value
            double score;   // key
            struct zskiplistNode *backward; // 后向指针，仅仅level[0]有
            struct zskiplistLevel {
                struct zskiplistNode *forward; // 前向指针，每一个level都有
                unsigned long span;     // 用来计算rank
            } level[];
        } zskiplistNode;

        typedef struct zskiplist {      // skiplist定义
            struct zskiplistNode *header, *tail; // 头尾元素
            unsigned long length; // 长度
            int level; // 元素到达的最高高度
        } zskiplist;

        typedef struct zset {
            dict *dict;     // 一个dict
            zskiplist *zsl;     // 一个skiplist
        } zset;

        zet 在元素数量较少时，采用ziplist来实现。在元素数量较大时，采用dict+skiplist来实现。
        zset的时间复杂度是O(logn)，和平衡树相当。并且对于范围查找更叫快速。而不是向平衡树那样依靠中序遍历。
        dict中保存elem-score対。而skiplist中保存score-elem対，对于排序更加快速。
    6. ziplist
        这是ziplist的内存布局，其中的entry相当复杂。
        <zlbytes> <zltail> <zllen> <entry> <entry> ... <entry> <zlend>
        zlbytes：整个ziplist的大小，包括zlbytes本身。
        zltail：最后一个entry的偏移，可以快速删除最后一个元素。
        zllen：ziplist中entry的数量
        zlend：特殊的entry，标志着结束。值是0xFF.
        ziplist 可以用来实现list，hash， zset

        这是ziplist entry的内存布局。
        <prevlen> <encoding> <entry-data>
    7. quicklist
        typedef struct quicklistNode {      // quicklist的节点
            struct quicklistNode *prev;
            struct quicklistNode *next;
            unsigned char *zl;              // 数据指针，如果当前节点没有被压缩，那么它指向一个ziplist结构，否则指向一个quicklistLZF结构
            unsigned int sz;             /* ziplist size in bytes */
            unsigned int count : 16;     /* count of items in ziplist */
            unsigned int encoding : 2;   /* RAW==1 or LZF==2 */
            unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */
            unsigned int recompress : 1; /* was this node previous compressed? */  // 当使用lindex的时候，需要判断这个节点是否被压缩了
            unsigned int attempted_compress : 1; /* node can't compress; too small */
            unsigned int extra : 10; /* more bits to steal for future usage */
        } quicklistNode;

        typedef struct quicklistLZF {
            unsigned int sz; /* LZF size in bytes*/
            char compressed[];
        } quicklistLZF;

        typedef struct quicklist {
            quicklistNode *head;
            quicklistNode *tail;
            unsigned long count;        /* total count of all entries in all ziplists */
            unsigned long len;          /* number of quicklistNodes */
            int fill : QL_FILL_BITS;              /* fill factor for individual nodes */    // 用来配置list-max-ziplist-size的值，节点中entry的数量，或者节点本身的大小
            unsigned int compress : QL_COMP_BITS; /* depth of end nodes not to compress;0=off */    // 用来配置list-compress-depth的值，2表示，两端各有两个节点不压缩。依次类推。
            unsigned int bookmark_count: QL_BM_BITS;
            quicklistBookmark bookmarks[];
        } quicklist;
```
2. 聚簇索引和非聚簇索引介绍一下？
```
    1. 两者的区别在于叶子节点是否存放了一整行的数据
    2. InnoDB主键使用聚簇索引，二级索引使用的是非聚簇索引，MyISAM使用的都是非聚簇索引。
    3. 聚簇索引查找目标数据时，理论上比非聚簇索引更快
    4. 聚簇索引插入很慢，需要遍历所有节点，但是由于叶子节点上面的数据很大，会因此付出IO代价。
    5. 一张表只允许创建一个聚簇索引。默认采用主键索引作为聚簇索引。
```
3. B+树的结构介绍一下？
```
    1. B+树基于B树和叶子节点顺序访问指针进行实现，它具有B树的平衡性并能够通过顺序访问指针来提高区间查询的性能。
    2. 在B+树中，叶子节点的Key从左向右非递减排序。
    3. B+树需要通过分裂，合并，旋转的方式来维护平衡性。
    4. 与红黑树相比： 平衡树查找的时间复杂度与树高有关，而B+树的出度大，高度低，因此查找次数更少。而且区间查找更快速。
    5. 与B树相比，非叶子节点不存放值。因此，一次IO操作可以读入更多的节点。加速查找。而且叶子节点有序，通过指针连接，区间查找更快速。
```
4. Hash冲突的解决办法？
```
    1. 开放地址法
    2. 再哈希法
    3. 链地址法
    4. 建立公共缓冲区
```
5. Redis 持久化有哪几种方式？
```
    1. RDB方式：默认开启，Redis会按照配置的指定时间将内存中的数据写入道磁盘上，创建一个dump.rdb文件，Redis启动时再恢复到内存。
       Redis会fork出一个子进程，将当前父进程的数据库拷贝到子进程的内存中来，然后由子进程负责写入到临时文件，持久化的过程结束了，再用
       这个临时文件替换掉上次的快照文件成为新的快照。
    2. AOF方式：以日志的形式记录每条写操作，不记录读操作。Redis启动时会根据日志内容从头到尾的执行一遍，完成持久化。
       因为采用追加的方式，会使的文件越来越大，针对这个问题，新增了重写机制，当日志文件大到一定程度的时候，会fork出一条子进程，将当前父进程
       内存中的数据拷贝到子进程中，每条记录对应一条set语句，写入临时文件中，之后再替换原来的aof文件。默认触发条件是日志文件大小翻倍，并且大于64M。
       在重写时，写入父进程数据库中命令也会被记录到缓存中，然后分别追加到新旧aof文件中。
```

6. Redis常见性能及解决方案？
```
    1. Master 最好不要做持久化工作，让Slave做。
    2. 如果数据比较重要，某个Slave开启AOF备份，策略设置为每秒同步一次。
    3. 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内。
    4. 主从复制不要采用图状结构，采用链状结构更稳定。方便解决单点故障。
```

7. Redis有哪几种淘汰旧数据的方案？
```
    1. volatile-ttl：从设置过期时间的数据集中选出最早要过期的
    2. volatile-lru: 从设置过期时间的数据集中选出最近最少使用的
    3. volatile-lfu: 从设置过期时间的数据集中选出最近访问次数最少的
    4. volatile-random: 从设置过期时间的数据集中随机选择一个
    5. allkeys-lru: 从整个数据集中选出最近最少使用的
    6. allkeys-lfu: 从整个数据集中选出最近最少使用的
    7. allkeys-random: 从整个数据集中随机选择一个
    8. noeviction: 不淘汰。
```

8. Redis 为什么是单线程的？
```
    1. 多线程涉及到锁，实现复杂。
    2. Redis的瓶颈在于内存和带宽，而不是CPU
    3. 虽然单进程无法发挥多核CPU的性能，但是可以通过在一个机器上开多个Redis来解决。
```

9. Redis 哨兵和复制？
```
    1. Sentinel可以管理多个Redis服务器，提供了监控，提醒，和自动的故障转移功能。
    2. Replication 负责让一个Redis服务器可以管理多个备份服务器。
```

10. Redis 哈希槽是什么？
```
    1. 当向Redis cluster中加入一个key，会根据crc16(key) mod 16384计算这个key应该放到哪个hash slot中，
       一个hash slot中会有很多的key和value。可以理解是表的分区。
    2. 便于动态的增加和删除节点，不需要停掉服务。
    3. key通过hash算法计算出应该放到哪个hash slot中，然后根据内存表来判断这个slot应该在哪个物理节点上。
    4. 哈希槽是16384（2^14）的原因：
        4.1 2^16个槽心跳信息达到8K，而2^14只有2K。
        4.2 crc16 対 2^14 取模，会使的key能够分布的很均匀。
        4.3 一个Redis集群通常不会超过1000个，那么一个节点上至少也有16个槽，可以分的到就行了。
    5. Redis集群最大节点数量也是16384 (2^14)个。
```

11. MYSQL的复制原理
```
    1. 主库上开启一个IO线程用于将写操作记录到二进制日志中。
    2. 从库上开启一个IO线程用于将主库上二进制日志中记录的写操作写入到自己的中继日志当中
    3. 从库上再开启一个SQL线程用于执行中继日志中的写操作，从而实现主从同步
    4. 二进制日志有三种格式
        4.1 语句格式
            4.1.1 使用了load_file(), uuid(), user(), sysdate() 的语句是无法记录的。
        4.2 行格式（可能会造成大量日志）
        4.3 语句和行混合格式（这个比较好）
```
12. InnoDB和MyISAM的区别？
```
    1. 事务的支持：InnoDB支持事务，MyISAM不支持事务。
    2. 锁的粒度：InnoDB为行级锁，MyISAM为标记锁。
    3. 索引类型：InnoDB为聚簇索引，MyISAM为非聚簇索引。
    4. 恢复完整度：InnoDB在数据库崩溃后容易恢复，MyISAM不容易恢复完整。
    5. 对于外键的支持：InnoDB支持，MyISAM不支持。
    6. 行数统计的快慢：InnoDB需要全表扫描，MyISAM可以从变量中直接读取。
    7. 存储结构：InnoDB中的所有表保存在同一个数据文件中。MyISAM中表分为.frm,.MYD,.MYI三个文件。
```
13. InnoDB存储引擎的四大特性
```
    1. 插入缓冲（Insert Buffer）：对于二级索引页的写操作，先保存在内存当中，等时机成熟在应用到二级索引页上。
    2. 二次写（Double Write）：将脏页先写入到二次写缓冲当中，然后在写入到共享表空间，最后才写入到独立表空间。保证
       数据页的可靠性。
    3. 自适应哈希索引（Adaptive Hash Index）：一般来说，我们实现从二级索引当中获取主键值，然后在聚簇索引当中获取行数据。
       我们可以対二级索引中的索引和行数据建立一个哈希关系。从而加快超找速度。
    4. 预读（Read Ahead）：64个page组成一个extend，如果当前extend当中的多个页被加载到内存当中，那么就将剩余的页也加载到
       内存当中。
```
14. char和varchar的区别？
```
    1. char是固定长度的，当varchar是变长的。
    2. char(50)表示这个变量占有50个字节。而varchar(50)表示这个变量最多可以占50个字节，最少可以占0个字节，但varchar需要一些额外空间来保存数据的长度。
```

15. InnoDB 日志种类，事务是如何通过日志实现的？
```
    1. 日志种类
        1.1 错误日志：记录错误信息，也记录一些警告和查询信息。
        1.2 查询日志：记录所有対数据库请求的信息，不论这些请求是否得到正确执行。
        1.3 慢查询日志：设置一个时间阈值，执行时间超过此时间的SQL语句都将被记录进来
        1.4 二进制日志：所有的写操作
        1.5 中继日志：部分写操作
    2. 四种事务级别
        2.1 读取未提交的内容：事务之间可以互相看到对方未提交的执行结果。
        2.2 读取已提交的内容：事务之间只能看到对方已提交的结果。
        2.3 可重复读：同一事务的不同实例在并发访问时会看到同样的数据行。可能会导致“幻读”。MySQL默认级别。
            A实例在读0-10行的数据，B实例向0-10行中插入新的行，A实例再次读，发现和上次不一样。这就是“幻读”。
        2.4 可串行化：事务之间都是排序的。在每个数据行上面加上共享锁。所以效率很低。
    3. 事务实现方式：
        3.1 通过redo和InnoDB的日志缓冲实现的。
```
16. MySQL数据库CPU飚到500%怎么处理？
```
    1. show processlist; 观察CPU最高，时间最长的进程，并关掉。
```
17. SQL 优化
```
    1. explain出来的各种item含义
        1.1 select_type: select字句的类型。
        1.2 table: 操作的表
        1.3 type: 访问类型
        1.4 possible_keys: 可以用的索引
        1.5 key: 实际使用的索引
        1.6 key_len: 索引中使用的字节数
        1.7 ref: 表的连接匹配条件
        1.8 extra: 不再其它列中，但是比较重要的信息
        1.9 partition: 分区信息
    2. profile 的意义
        2.1 查询SQL语句执行了多长时间。
        2.2 查询SQL语句占用的CPU和内存。
```
18. MySQL索引的最左前缀原则？
```
    1. 有一个复合索引index(a, b, c)
    where a = 1 and b = 2; 能用上。
    where a = 1 and c = 3; 能用上a
    where b = 2 and c = 1; 不能用上。
```
19. MySQL主从服务器，主服务器是InnoDB，从服务器是MyISAM，应用会遇到什么问题？
```
    1. MyISAM是表级锁，在同步的时候，无法提供读服务。
    2. MyISAM不支持事务，突然宕机会导致数据丢失。
```
20. MySQL语句应该考虑哪些安全性？
```
    1. 防止SQL注入，対特殊字符进行转义，使用预编译sql语句绑定。
    2. 使用最小权限原则，为不同动作建立不同的账户。
    3. sql出错时，不要把数据库的出错信息暴露给客户端。
```
21. MySQL有哪些索引类型？
```
    1. 普通索引：可重复
    2. 唯一索引：不可重复，可为空
    3. 主键索引：不为空
    4. 全文索引：like %word%
    5. 复合索引：index(A,B,C),最左前缀匹配
    6. 外键索引
```
22. MySQL中的乐观锁和悲观锁？
```
    1. 乐观锁：它实际上并不是锁，一般用CAS（Check And Set）来实现。给数据库增加一个版本或时间戳字段。
       在读行数据的时候，需要读取这个版本字段。在写数据的时候要比较之前取数据的时候的版本号与现在的版本号
       是否相等，相等就可以写入；否则，拒绝写入。
    2. 悲观锁：它就是一把锁。在访问行数据的时候，会给这一行加上一把锁，访问结束后，取下这把锁。
```
23. MySQL主键，超键，候选键，外键？
```
    1. 主键：可以唯一标识行数据的列元组，不可以有空值，也不可以重复。
    2. 候选键：可以唯一标识行数据的列元组，不存在冗余列。
    3. 超键：存在冗余列。冗余列就是加不加都可以唯一标识行数据。
    4. 外键：另一个的主键。
```
24. MySQL 视图的作用，视图可以更新吗？
```
    1. 虚拟的表，不包含数据。
    2. 用来保护数据，简化检索。
    3. 大部分视图不可以更新。
```
25. MySQL 数据库范式
```
    1. 第一范式：每一列都不可以被分割，没有重复的列。不足第一范式就不是关系型数据库。
    2. 第二范式：非主属性完全依赖主属性。
    3. 第三范式：非主属性不依赖于其它非主属性。
```
26. MySQL 数据库优化的思路？
```
    1. 语句优化
        1.1 where 子句中尽量避免 <>, ！=， 否则会退化成全表扫描。
        1.2 where 子句中尽量避免null判断，否则会退化成全表扫描。可在numer的null值上设置为0.
        1.3 使用 exist 比 in更好。
        1.4 where子句代替having。因为having只会在数据被查询出来后才对结果进行过滤。
    2. 索引优化
        2.1 经常搜索的列上建索引。
        2.2 主键的列上建索引。
        2.3 order by 子句上的列建索引。
        2.4 where 子句上的列建索引。
        2.5 查询中很少使用的列上不要建索引。
        2.6 只有很少数据值的列上也不要建索引。
        2.7 text，blob类型的列上不要建索引。
        2.8 索引的代价：
            2.8.1 占据而外的空间
            2.8.2 更新索引需要花时间
    3. 数据库结构优化
        3.1 范式优化
        3.2 反范式优化，适当增加冗余，减少join的使用
        3.3 表的拆分。
    4. 不使用外键索引
        外键索引的维护需要消耗资源，可以在应用层做判断。
```
27. MySQL 触发器
```
    1. 六种，before/after update/delete/insert.
```
28. Reids 雪崩，穿透，击穿？
```
    1. 雪崩：同一时刻，多个key过期。过期时间随机化。
    2. 穿透：元素不存在id=-1。redis中设置为null
    3. 击穿：热点数据，访问过多，当前节点当掉，然后由于故障转移，导致所有节点都挂掉。最后数据库也就挂掉了。限流，使用kafka中间件。
```


算法：
1. 基本排序中，哪些是稳定的，哪些是不稳定的？
```
    1. 稳定排序：冒泡排序，插入排序 ，归并排序，基数排序
    2. 不稳定排序：选择排序，快速排序，希尔排序，堆排序
```
2. 如何对一个20GB的大文件进行排序？
```
    1. 采用外归并排序，假设机器的内存为100M，要对900M的数据进行排序
    2. 依次读入100M的数据到内存中，采用某种常规方式（快速排序，堆排序等）在内存中完成排序
    3. 处理完成后，会产生9个100M的有序的临时文件，位于磁盘上
    4. 读取每个文件的前10M到内存，共占用90M。最后的10M用作输出缓冲区。
    5. 执行9路归并排序，将结果写入道输出缓冲区，一旦输出缓冲区满了，就将缓冲区的数据写入到磁盘上，清空缓冲区。
    6. 当9个输入缓冲区有一个变空时，就从这个缓冲区对应的文件中读取下一个10M文件，除非这个文件已经读取完了。
```
3. 如何判断两个无环单链表是否有交叉点？
```
    1. 分别遍历两个链表，若最后一个节点的值相等，则有交叉点；反之，没有。
```
4. 如何判断一个单链表有没有环，并找出交叉点？
```
    1. 分别创建两个指针指向链表的头节点，第一个指针每次走1步，第二个指针每次走2步。看看是否会有指向相同元素的时刻。
    2. 如果存在指向相同元素，则有环；反之，无环
```
5. 手写一个快速排序？
```

func partition(A []int, lo, hi int) int  {
	pivot := A[hi]
	i := lo
	for j:=lo; j<=hi; j++ {
		if A[j] < pivot {
			A[i], A[j] = A[j], A[i]
			i ++
		}
	}
	A[i], A[hi] = A[hi], A[i]
	return i
}

func quickSort(A []int, lo, hi int) {
	if lo < hi {
		p := partition(A, lo, hi)
		quickSort(A, lo, p-1)
		quickSort(A, p+1, hi)
	}
	
}

```
6. 给一个二叉树，判断是否是二叉搜索树？
```
func isValidBST(root *TreeNode) bool {
	return helper(root, nil, nil)
}


// helper ...
func helper(root, min, max *TreeNode) bool {
	if root == nil {
		return true
	}

	if min != nil && min.Val >= root.Val {
		return false
	}

	if max != nil && max.Val <= root.Val {
		return false
	}

	return helper(root.Left, min, root) &&
		helper(root.Right, root, max)
}
```

中间件
1. 介绍一下消息中间件 kafka
```
    1. 为啥要是用消息队列？
        1.1 解藕：消息的生产和消费是两个独立的部分，方便程序修改
        1.2 异步通信：生产者只负责生产，消费者只负责消费，两者速率可以有差别。从而提高系统的运行效率。
        1.3 削峰：比如秒杀活动，避免系统被突发流量弄崩溃
        1.4 顺序保证：消息消费的顺序就是生产的顺序
        1.5 送达保证：只有得到消费者已经消费掉这个消息后，才会将这个消息删除；否则，一直会存在。
    2. kafka中的名词解释
        2.1 broker: 代理商，kafka集群包含1个到多个服务器，每个服务器被称为一个broker
        2.2 topic：主题，每个消息都有一个主题
        2.3 partition：物理分区，消息实际存放的地方。每个partition对应一个文件夹，包含索引和日志信息
        2.4 producer：生产者，向broker发送消息的对象
        2.5 consumer: 消费者，从broker读取消息的对象。多个消费者可以构成一个消费者组。不同消费者组里的成员可以消费
            同一个分区，但是同一消费者组里的成员不能消费同一分区。
    3. 分区的选择方式
        3.1 如果消息没有key，那么采用轮询的方式选择分区。
        3.2 如果消息有key，那么取hash(key)%partition_num的值来选择分区
        3.3 注意，同一分区内的消息是有序的，但是不同分区的数据不是有序的。
        3.4 分区删除旧消息的方式：
            3.4.1 时间方式：默认7天
            3.4.2 大小方式：默认1GB
            3.4.5 检查间隔：默认每5分钟检查一次
    4. Leader 和 Follower 复制
        4.1 Leader 完全负责读和写，Followers仅仅复制，在Leader挂掉之后选取出新的Leader
        4.2 ISR(In Sync List): 如果一个Follower落后太多（时间或者消息数量上），就将它从ISR队列中移除。
        4.3 消费者可以指定消息送达的可靠性：发送消息后不需要获得broker的应答，或者仅仅Leader的应答，或者所有Follower的应答
    5. Consumer Rebanlance 消费者重新平衡是由Zookeeper管理的。
    6. 如何在分区中找到对应的offset
        6.1 通过offset从索引文件中找到最近的索引
        6.2 利用该索引值在日志文件中结合offset顺序查找，直到找到消息
        6.3 使用稀疏索引的方式，减少了索引文件的大小。
```

2. 介绍一下Elastic Stack？
```
    1. 主要包括Filebeat, Logstash, Elasticsearch, Kibana四个组成部分。
    2. Filebeat：
        负责日志收集，安装包小。安装在需要采集日志的服务器上。可以将数据发送给logstash或者elasticsearch.
        Packetbeat负责搜集网络流量数据，Topbeat负责收集系统，进程和文件级别的CPU和内存的使用情况。
        Winlogbeat负责搜集windows事件日志数据。可以和logstash之间加密通讯。
    3. Logstash：
        负责日志的收集和处理，安装包比较大。配置文件包括input,filter,output三部分。filter部分主要対日志进行
        模式匹配。
    4. Elasticsearch：
        分布式搜索和分析引擎，全文索引。
    5. Kibana：
        数据可视化展示。于Elasticsearch配合使用。可以更具数据绘制各种图表。
    6. Elasticsearch 选取master？
        6.1 先确定候选主节点有那些
        6.2 再候选主节点中选出id值较小的那一个
    7. Elasticsearch 索引文档的过程？
        7.1 客户端向集群中的某个节点发送文档写入请求
        7.2 该节点根据文档_id值计算确定文档属于的主分片，并转发请求到主分片上
        7.3 主分片写入该文档，待写入完成后，再同步到副分片上
        7.4 待收到所有副分片报告成功后，返回给最初的节点写入成功。
        7.5 最初的节点再返回给客户端成功的消息。
    8. Elasticsearch 搜索的过程？
        8.1 query-1：每个节点在本地查询，结果放在本地队列当中
        8.2 query-2：将本地队列中结果放入到协调节点上，得到全局排序表。
        8.3 fetch：协调节点将所有文档返回给客户端。
    9. Elasticsearch 删除和更新文档的过程？
        9.1 删除和更新都是写操作，但是ES中的文档是不可变的，因此并不是物理删除，而是逻辑删除（被过滤掉了）。
        9.2 磁盘上的每个段都有一个响应的.del文件。当收到删除请求后，文档并没有被物理删除，而是在.del文件中
            被标记为删除。该文档仍然可以被索引，但是结果中被过滤掉了。当段合并的时候，在.del文件中被标记的
            文档不会被写入到新的段中。
        9.3 当文档被更新时，也是类似的。每个文档都有一个版本号（_version）,旧版本的文档会在.del文件中标记为
            删除，新版本的文件会被索引到一个新段。旧版本仍然查询到，但是在结果中被过滤掉了。
```

3. docker 介绍一下？
```
    1. docker 是一个容器工具
    2. docker network driver
        2.1 Host
            使用主机的网络空间
        2.2 Bridge
            连接到同一个brige上面的容器可以相互通信。分为默认bridge和用户自定义bridge。docker0是三层网桥。
            容器空间的eth0和用户空间的docker0通过虚拟网卡veth进行通信。然后docker0和用户空间的ens33进行通信，从而与外界通信。
            容器内部和外部通过masquerade/nat和port mapping 来通信。
        2.3 Overlay
            利用overlay网络来实现不同主机上的容器间的通信，用于docker swarm。
            利用mac-in-udp来封转消息。
        2.4 Macvlan
            需要一个网关地址。
        2.5 none
            容器与外界世界隔离
    3. docker storage
        3.1 volume
            最为推荐。docker管理。
        3.2 bind mounts
            用于映射配置文件。
        3.3 tmpfs mounts
            数据映射到主机的内存当中。断电即毁。
```

4. kubernetes 介绍一下？
```
    1. 类似于docker swarm，用来管理位于多个主机上的多个容器间通信问题产生的。
    2. Service
       用于对外暴露服务，service需要在deployment之前创建。这样在利用deployment创建pods的时候，可以让pods携带这些service信息到node上面去。
       kube-proxy有三种模式：
        2.1 user space proxy mode: 用户空间代理模式
        2.2 iptables proxy mode: iptables 代理模式：内核空间，比用户空间调度更快。
        2.3 ipvs proxy mode： ipvs代理模式，内核空间，比iptables proxy mode 更快。支持多种调度算法
       服务发现有两种方式：一种环境变量，之后创建的pod都会存有这些环境变量。另一种是dns，推荐。
       对于不需要向外提供服务的service，被称为headless service. 没有cluster ip，kube-proxy不处理。
       服务类型：
        1. Cluster IP: 仅仅cluster内部可以访问
        2. NodePort: 将服务暴露到主机的所有网卡上
        3. LoadBalancer: 利用云服务商提供loadbalancer
        4. ExternalName： 使用CNAME记录。
    3. Deployment
       取代ReplicaSet，可以用来描述目标状态。数量，可以滚动升级，降级。暂停部署。
    4. Node
       每个主机是一个node，每个node上面可以有多个pod。因为每个主机的物理情况（CPU和内存）不同。
    5. Pod
       kubernetes调度的最小单位。
       不要手动创建pod，利用deployment来管理pod更好。每个pod都有一个ip地址
    5. 每个节点上都要有kubelet，用于和master通信。还要有kube-proxy用户对外暴露服务。
    6. master上的etcd用于保存整个集群的状态。一般情况下，master节点不参与工作调度。 
```

5. raft 协议介绍一下？
```
    1. 简单介绍
        通常一个raft集群包含多个节点。每个节点服务器只可能处于以下三个状态之一。Leader, Follower, Candidate.
        正常情况下，只有一个节点是Leader,其余都是Follower。只有在进行Leader选取的时候才会出现Cadidate状态。
        所有的用户请求都是由Leader完成的。如果请求被发给了Follower，那么Follower也会将这个请求转发给Leader来处理。
        raft通过将时间分隔成term，每个term开始阶段都是Leader选取。term是一个单调递增的整数。
        RequestVote RPC：在Leader选取阶段，Candidate发送给其余节点服务器的消息。
        AppendEntries RPC：Leader用来给Follower提供操作日志的。
    2. Leader选举
        采用过半数选举。
        Leader down掉之后，每个Follower都声明自己是Candidate。然后发送RequestVote RPC，希望对方向自己投票。
        会存在下面三种情况：
        1. 自己获得过半数投票，称为Leader
            每个服务器节点只能够投一次票，遵循谁先到投给谁的策略。一旦成为Leader后，就像其余Candidate发送消息声明自己就是新任Leader。
        2. 其它服务器节点获得过半数投票
            当收到其它节点发送过来的AppendEntries RPC消息后，比较term值是否比自己的要大，如果比自己的要大，就认为它是新任Leader；否则拒绝这个消息。
        3. 在选举时间内没有人成为Leader
            本轮term结束。为了降低再次出现没有Leader状况的概率，所有的服务器节点等待不同的随机时间再次并行向其余服务器节点发出RequestVote RPC消息。
    3. Log 复制
        Log 日志通过AppendEntries RPC发送给所有的Follower。
        只有当收到过半数（包括自己）的确认消息后，才会提交这个操作。
        如果出现不一致，那么Leader的日志会覆盖Follower的日志。
    4. Safty
        如果想要成为Candidate，那么就必须要包含上一个term所有的日志记录。
    5. Log Compact
        raft的日志随着时间会越来越多，可以对这些日志进行snapshot保存。然后删除掉这些日志。sanpshot只会保存最终状态，不会保存修改的操作过程。
```